{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4607aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up coordinate transformer (WGS84 -> RD New)...\n",
      "Loading JSON files...\n",
      "\n",
      "Processing amsterdam_green_2020_parks_only.json...\n",
      "  Loaded 322 elements\n",
      "\n",
      "Processing amsterdam_green_2024_parks_only.json...\n",
      "  Loaded 377 elements\n",
      "\n",
      "Processing amsterdam_green_2020_wood_forest.json...\n",
      "  Loaded 8600 elements\n",
      "\n",
      "Processing amsterdam_green_2024_wood_forest.json...\n",
      "  Loaded 10693 elements\n",
      "\n",
      "============================================================\n",
      "Total elements loaded: 19992\n",
      "\n",
      "Processing geometries and computing centroids...\n",
      "  Processed 500/19992...\n",
      "  Processed 1000/19992...\n",
      "  Processed 1500/19992...\n",
      "  Processed 2000/19992...\n",
      "  Processed 2500/19992...\n",
      "  Processed 3000/19992...\n",
      "  Processed 3500/19992...\n",
      "  Processed 4000/19992...\n",
      "  Processed 4500/19992...\n",
      "  Processed 5000/19992...\n",
      "  Processed 5500/19992...\n",
      "  Processed 6000/19992...\n",
      "  Processed 6500/19992...\n",
      "  Processed 7000/19992...\n",
      "  Processed 7500/19992...\n",
      "  Processed 8000/19992...\n",
      "  Processed 8500/19992...\n",
      "  Processed 9000/19992...\n",
      "  Processed 9500/19992...\n",
      "  Processed 10000/19992...\n",
      "  Processed 10500/19992...\n",
      "  Processed 11000/19992...\n",
      "  Processed 11500/19992...\n",
      "  Processed 12000/19992...\n",
      "  Processed 12500/19992...\n",
      "  Processed 13000/19992...\n",
      "  Processed 13500/19992...\n",
      "  Processed 14000/19992...\n",
      "  Processed 14500/19992...\n",
      "  Processed 15000/19992...\n",
      "  Processed 15500/19992...\n",
      "  Processed 16000/19992...\n",
      "  Processed 16500/19992...\n",
      "  Processed 17000/19992...\n",
      "  Processed 17500/19992...\n",
      "  Processed 18000/19992...\n",
      "  Processed 18500/19992...\n",
      "  Processed 19000/19992...\n",
      "  Processed 19500/19992...\n",
      "  Successfully processed 19838/19992 elements\n",
      "  Failed: 154 elements\n",
      "\n",
      "============================================================\n",
      "SUMMARY:\n",
      "============================================================\n",
      "\n",
      "Total green spaces: 19838\n",
      "\n",
      "By type:\n",
      "type\n",
      "forest    18866\n",
      "park        689\n",
      "wood        273\n",
      "garden       10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "By year:\n",
      "source_year\n",
      "2024    10997\n",
      "2020     8841\n",
      "Name: count, dtype: int64\n",
      "\n",
      "By grid cell:\n",
      "grid_cell\n",
      "cell_0_0    3312\n",
      "cell_0_1    5226\n",
      "cell_0_2    3381\n",
      "cell_1_0    3038\n",
      "cell_1_1    4229\n",
      "cell_1_2     652\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Named features: 19838/19838 (100.0%)\n",
      "\n",
      "Area statistics:\n",
      "  Total area: 119,812,666 m² (119.81 km²)\n",
      "  Average: 6,040 m²\n",
      "  Median: 901 m²\n",
      "  Largest: 8,978,684 m²\n",
      "\n",
      "Largest green spaces:\n",
      "                name  type     area_m2 source_year\n",
      "1    Amsterdamse Bos  park  8978684.36        2020\n",
      "43   Amsterdamse Bos  park  8978684.36        2020\n",
      "313  Amsterdamse Bos  park  8970231.89        2024\n",
      "359  Amsterdamse Bos  park  8970231.89        2024\n",
      "540       Sloterpark  park  1342832.67        2024\n",
      "\n",
      "✓ Saved to green_areas.csv\n",
      "\n",
      "Sample rows:\n",
      "     osm_id                name  type  centroid_lat  centroid_lon     area_m2 grid_cell source_year\n",
      "0  26493165       Kasterleepark  park     52.348689      4.810465    50113.77  cell_0_0        2020\n",
      "1  26517033     Amsterdamse Bos  park     52.313295      4.832835  8978684.36  cell_0_0        2020\n",
      "2  46785402  Sportpark Overburg  park     52.313189      4.843898    53371.17  cell_0_0        2020\n",
      "3  58169403                      park     52.331408      4.784210   116615.32  cell_0_0        2020\n",
      "4  62923595          Wandelpark  park     52.342463      4.771932    93325.07  cell_0_0        2020\n",
      "5  74604095     Forintplantsoen  park     52.346620      4.786073     8606.72  cell_0_0        2020\n",
      "6  75637761                      park     52.320779      4.839951    76898.90  cell_0_0        2020\n",
      "7  75637918          Speelweide  park     52.310205      4.831819    45422.66  cell_0_0        2020\n",
      "8  75638222                      park     52.319812      4.831654     9586.09  cell_0_0        2020\n",
      "9  75638513          Bizonweide  park     52.313597      4.826962    49005.65  cell_0_0        2020\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "from pyproj import Transformer\n",
    "\n",
    "def load_json_file(filename):\n",
    "    \"\"\"Load a JSON file and return elements\"\"\"\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data.get('elements', [])\n",
    "\n",
    "def extract_geometry(element):\n",
    "    \"\"\"Extract geometry from OSM element and return Shapely object in WGS84\"\"\"\n",
    "    elem_type = element.get('type')\n",
    "    \n",
    "    if elem_type == 'node':\n",
    "        # Point feature\n",
    "        lat = element.get('lat')\n",
    "        lon = element.get('lon')\n",
    "        if lat and lon:\n",
    "            return Point(lon, lat)\n",
    "    \n",
    "    elif elem_type == 'way':\n",
    "        # LineString or Polygon\n",
    "        geometry = element.get('geometry', [])\n",
    "        if geometry and len(geometry) >= 3:\n",
    "            coords = [(pt['lon'], pt['lat']) for pt in geometry]\n",
    "            # Check if it's a closed polygon\n",
    "            if len(coords) >= 4 and coords[0] == coords[-1]:\n",
    "                return Polygon(coords)\n",
    "            else:\n",
    "                # Not closed - could be LineString or unclosed way\n",
    "                # For ways, try closing it if it makes sense\n",
    "                if len(coords) >= 3:\n",
    "                    return Polygon(coords + [coords[0]])\n",
    "                return LineString(coords)\n",
    "    \n",
    "    elif elem_type == 'relation':\n",
    "        # Complex multipolygons\n",
    "        geometry = element.get('geometry', [])\n",
    "        if geometry and len(geometry) >= 3:\n",
    "            coords = [(pt['lon'], pt['lat']) for pt in geometry]\n",
    "            # Ensure closed\n",
    "            if coords[0] != coords[-1]:\n",
    "                coords.append(coords[0])\n",
    "            if len(coords) >= 4:\n",
    "                return Polygon(coords)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_feature_type(element):\n",
    "    \"\"\"Determine if element is park, wood, or forest\"\"\"\n",
    "    tags = element.get('tags', {})\n",
    "    \n",
    "    if tags.get('leisure') == 'park':\n",
    "        return 'park'\n",
    "    elif tags.get('leisure') == 'garden':\n",
    "        return 'garden'\n",
    "    elif tags.get('natural') == 'wood':\n",
    "        return 'wood'\n",
    "    elif tags.get('landuse') == 'forest':\n",
    "        return 'forest'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "def get_name(element):\n",
    "    \"\"\"Extract name from tags\"\"\"\n",
    "    tags = element.get('tags', {})\n",
    "    return tags.get('name', tags.get('name:en', ''))\n",
    "\n",
    "def process_element(element, transformer):\n",
    "    \"\"\"Process a single OSM element with proper projection\"\"\"\n",
    "    # Get geometry in WGS84 (EPSG:4326)\n",
    "    geom_wgs84 = extract_geometry(element)\n",
    "    if geom_wgs84 is None:\n",
    "        return None\n",
    "    \n",
    "    # Transform to RD New (EPSG:28992) for accurate area calculation\n",
    "    geom_rd = transform_geometry(geom_wgs84, transformer)\n",
    "    \n",
    "    # Calculate centroid in WGS84 (lat/lon)\n",
    "    centroid_wgs84 = geom_wgs84.centroid\n",
    "    \n",
    "    # Calculate area in m² using RD New projection\n",
    "    area_m2 = geom_rd.area if hasattr(geom_rd, 'area') else 0\n",
    "    \n",
    "    # Extract metadata\n",
    "    osm_id = element.get('id')\n",
    "    feature_type = get_feature_type(element)\n",
    "    name = get_name(element)\n",
    "    grid_cell = element.get('grid_cell', '')\n",
    "    \n",
    "    return {\n",
    "        'osm_id': osm_id,\n",
    "        'name': name,\n",
    "        'type': feature_type,\n",
    "        'centroid_lat': centroid_wgs84.y,\n",
    "        'centroid_lon': centroid_wgs84.x,\n",
    "        'area_m2': round(area_m2, 2),\n",
    "        'grid_cell': grid_cell,\n",
    "        'geometry_wkt': geom_wgs84.wkt  # Store WGS84 for reference\n",
    "    }\n",
    "\n",
    "def transform_geometry(geom, transformer):\n",
    "    \"\"\"Transform geometry from WGS84 to RD New\"\"\"\n",
    "    if isinstance(geom, Point):\n",
    "        x, y = transformer.transform(geom.y, geom.x)\n",
    "        return Point(x, y)\n",
    "    elif isinstance(geom, Polygon):\n",
    "        exterior_coords = [transformer.transform(lat, lon) for lon, lat in geom.exterior.coords]\n",
    "        return Polygon(exterior_coords)\n",
    "    elif isinstance(geom, LineString):\n",
    "        coords = [transformer.transform(lat, lon) for lon, lat in geom.coords]\n",
    "        return LineString(coords)\n",
    "    return geom\n",
    "\n",
    "def main():\n",
    "    print(\"Setting up coordinate transformer (WGS84 -> RD New)...\")\n",
    "    # Create transformer: WGS84 (EPSG:4326) -> RD New (EPSG:28992)\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:28992\", always_xy=False)\n",
    "    \n",
    "    print(\"Loading JSON files...\")\n",
    "    \n",
    "    # Load all files\n",
    "    files = {\n",
    "        '2020_parks': '../data/amsterdam_green_2020_parks_only.json',\n",
    "        '2024_parks': '../data/amsterdam_green_2024_parks_only.json',\n",
    "        '2020_wood_forest': '../data/amsterdam_green_2020_wood_forest.json',\n",
    "        '2024_wood_forest': '../data/amsterdam_green_2024_wood_forest.json'\n",
    "    }\n",
    "    \n",
    "    all_elements = []\n",
    "    \n",
    "    for file_key, filename in files.items():\n",
    "        print(f\"\\nProcessing {filename}...\")\n",
    "        try:\n",
    "            elements = load_json_file(filename)\n",
    "            print(f\"  Loaded {len(elements)} elements\")\n",
    "            \n",
    "            # Add year and source info\n",
    "            year = '2020' if '2020' in file_key else '2024'\n",
    "            \n",
    "            for elem in elements:\n",
    "                elem['source_year'] = year\n",
    "                elem['source_file'] = file_key\n",
    "            \n",
    "            all_elements.extend(elements)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"  Warning: File not found: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Error loading {filename}: {e}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Total elements loaded: {len(all_elements)}\")\n",
    "    \n",
    "    # Process all elements\n",
    "    print(\"\\nProcessing geometries and computing centroids...\")\n",
    "    processed = []\n",
    "    failed = 0\n",
    "    \n",
    "    for i, elem in enumerate(all_elements):\n",
    "        if (i + 1) % 500 == 0:\n",
    "            print(f\"  Processed {i + 1}/{len(all_elements)}...\")\n",
    "        \n",
    "        try:\n",
    "            result = process_element(elem, transformer)\n",
    "            if result:\n",
    "                result['source_year'] = elem.get('source_year')\n",
    "                result['source_file'] = elem.get('source_file')\n",
    "                processed.append(result)\n",
    "            else:\n",
    "                failed += 1\n",
    "        except Exception as e:\n",
    "            failed += 1\n",
    "            if failed <= 5:  # Only print first few errors\n",
    "                print(f\"  Warning: Failed to process element {elem.get('id')}: {e}\")\n",
    "    \n",
    "    print(f\"  Successfully processed {len(processed)}/{len(all_elements)} elements\")\n",
    "    if failed > 0:\n",
    "        print(f\"  Failed: {failed} elements\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(processed)\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SUMMARY:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nTotal green spaces: {len(df)}\")\n",
    "    print(f\"\\nBy type:\")\n",
    "    print(df['type'].value_counts())\n",
    "    print(f\"\\nBy year:\")\n",
    "    print(df['source_year'].value_counts())\n",
    "    print(f\"\\nBy grid cell:\")\n",
    "    print(df['grid_cell'].value_counts().sort_index())\n",
    "    print(f\"\\nNamed features: {df['name'].notna().sum()}/{len(df)} ({100*df['name'].notna().sum()/len(df):.1f}%)\")\n",
    "    print(f\"\\nArea statistics:\")\n",
    "    print(f\"  Total area: {df['area_m2'].sum():,.0f} m² ({df['area_m2'].sum()/1_000_000:,.2f} km²)\")\n",
    "    print(f\"  Average: {df['area_m2'].mean():,.0f} m²\")\n",
    "    print(f\"  Median: {df['area_m2'].median():,.0f} m²\")\n",
    "    print(f\"  Largest: {df['area_m2'].max():,.0f} m²\")\n",
    "    \n",
    "    # Show largest parks\n",
    "    print(f\"\\nLargest green spaces:\")\n",
    "    print(df.nlargest(5, 'area_m2')[['name', 'type', 'area_m2', 'source_year']])\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = '../data/green_areas.csv'\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"\\n✓ Saved to {output_file}\")\n",
    "    \n",
    "    # Show sample\n",
    "    print(f\"\\nSample rows:\")\n",
    "    cols_to_show = ['osm_id', 'name', 'type', 'centroid_lat', 'centroid_lon', 'area_m2', 'grid_cell', 'source_year']\n",
    "    print(df[cols_to_show].head(10).to_string())\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61cb3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "Total rows: 19838\n",
      "\n",
      "Breakdown by year:\n",
      "source_year\n",
      "2024    10997\n",
      "2020     8841\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Duplicates based on (osm_id, source_year):\n",
      "Found 628 duplicate rows\n",
      "\n",
      "Sample duplicates:\n",
      "        osm_id                     name  type  source_year source_file\n",
      "1     26517033          Amsterdamse Bos  park         2020  2020_parks\n",
      "2     46785402       Sportpark Overburg  park         2020  2020_parks\n",
      "11    98133437  Dr. Jac. P. Thijssepark  park         2020  2020_parks\n",
      "19   311453250             Seifertplein  park         2020  2020_parks\n",
      "22   403847003         Stadspark Osdorp  park         2020  2020_parks\n",
      "25   485022427        Kersenbloesempark  park         2020  2020_parks\n",
      "29   536787142         Piet Wiedijkpark  park         2020  2020_parks\n",
      "33     6316270             Sarphatipark  park         2020  2020_parks\n",
      "43    26517033          Amsterdamse Bos  park         2020  2020_parks\n",
      "65    44213014               Vondelpark  park         2020  2020_parks\n",
      "68    46785402       Sportpark Overburg  park         2020  2020_parks\n",
      "74    98133437  Dr. Jac. P. Thijssepark  park         2020  2020_parks\n",
      "85   126602802       Nelson Mandelapark  park         2020  2020_parks\n",
      "86   151332009                      NaN  park         2020  2020_parks\n",
      "88   151332014                      NaN  park         2020  2020_parks\n",
      "90   151332029                      NaN  park         2020  2020_parks\n",
      "117  355478180    Natuurpark Spoorzicht  park         2020  2020_parks\n",
      "129  545030634         Galileïplantsoen  park         2020  2020_parks\n",
      "142   13308960               Diemerpark  park         2020  2020_parks\n",
      "149  126602802       Nelson Mandelapark  park         2020  2020_parks\n",
      "\n",
      "============================================================\n",
      "After deduplication:\n",
      "Total rows: 19523\n",
      "Removed: 315 duplicate rows\n",
      "\n",
      "Breakdown by year:\n",
      "source_year\n",
      "2024    10836\n",
      "2020     8687\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Breakdown by type:\n",
      "type\n",
      "forest    18600\n",
      "park        642\n",
      "wood        271\n",
      "garden       10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ Saved deduplicated data to green_areas_clean.csv\n",
      "\n",
      "============================================================\n",
      "Area statistics (cleaned data):\n",
      "  Total area: 95,213,053 m² (95.21 km²)\n",
      "  Average: 4,877 m²\n",
      "  Median: 887 m²\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV\n",
    "df = pd.read_csv('../data/green_areas.csv')\n",
    "\n",
    "print(\"Original data:\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"\\nBreakdown by year:\")\n",
    "print(df['source_year'].value_counts())\n",
    "\n",
    "# Check for duplicates based on osm_id and year\n",
    "print(f\"\\nDuplicates based on (osm_id, source_year):\")\n",
    "duplicates = df[df.duplicated(subset=['osm_id', 'source_year'], keep=False)]\n",
    "print(f\"Found {len(duplicates)} duplicate rows\")\n",
    "\n",
    "if len(duplicates) > 0:\n",
    "    print(\"\\nSample duplicates:\")\n",
    "    print(duplicates[['osm_id', 'name', 'type', 'source_year', 'source_file']].head(20))\n",
    "\n",
    "# Remove duplicates - keep first occurrence\n",
    "df_clean = df.drop_duplicates(subset=['osm_id', 'source_year'], keep='first')\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"After deduplication:\")\n",
    "print(f\"Total rows: {len(df_clean)}\")\n",
    "print(f\"Removed: {len(df) - len(df_clean)} duplicate rows\")\n",
    "print(f\"\\nBreakdown by year:\")\n",
    "print(df_clean['source_year'].value_counts())\n",
    "print(f\"\\nBreakdown by type:\")\n",
    "print(df_clean['type'].value_counts())\n",
    "\n",
    "\n",
    "# Save cleaned data\n",
    "output_file = '../data/green_areas_clean.csv'\n",
    "df_clean.to_csv(output_file, index=False, encoding='utf-8')\n",
    "print(f\"\\n✓ Saved deduplicated data to {output_file}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Area statistics (cleaned data):\")\n",
    "print(f\"  Total area: {df_clean['area_m2'].sum():,.0f} m² ({df_clean['area_m2'].sum()/1_000_000:,.2f} km²)\")\n",
    "print(f\"  Average: {df_clean['area_m2'].mean():,.0f} m²\")\n",
    "print(f\"  Median: {df_clean['area_m2'].median():,.0f} m²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3be0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Green spaces: 19523 entries\n",
      "\n",
      "DEBUG - source_year info:\n",
      "  Unique values: [2020 2024]\n",
      "  Data type: int64\n",
      "  Sample rows:\n",
      "     osm_id                name  type  source_year\n",
      "0  26493165       Kasterleepark  park         2020\n",
      "1  26517033     Amsterdamse Bos  park         2020\n",
      "2  46785402  Sportpark Overburg  park         2020\n",
      "3  58169403                 NaN  park         2020\n",
      "4  62923595          Wandelpark  park         2020\n",
      "\n",
      "After conversion:\n",
      "  2020: 8687 entries\n",
      "  2024: 10836 entries\n",
      "Buurten: 439 entries\n",
      "\n",
      "============================================================\n",
      "CALCULATING METRICS FOR 2020\n",
      "============================================================\n",
      "Using 8687 green spaces from 2020\n",
      "  Processing 50/439...\n",
      "  Processing 100/439...\n",
      "  Processing 150/439...\n",
      "  Processing 200/439...\n",
      "  Processing 250/439...\n",
      "  Processing 300/439...\n",
      "  Processing 350/439...\n",
      "  Processing 400/439...\n",
      "\n",
      "============================================================\n",
      "CALCULATING METRICS FOR 2024\n",
      "============================================================\n",
      "Using 10836 green spaces from 2024\n",
      "  Processing 50/439...\n",
      "  Processing 100/439...\n",
      "  Processing 150/439...\n",
      "  Processing 200/439...\n",
      "  Processing 250/439...\n",
      "  Processing 300/439...\n",
      "  Processing 350/439...\n",
      "  Processing 400/439...\n",
      "\n",
      "✓ Saved results to buurt_green_metrics.csv\n",
      "\n",
      "============================================================\n",
      "SUMMARY STATISTICS\n",
      "============================================================\n",
      "\n",
      "2020:\n",
      "  Avg distance to green: 192.80 m\n",
      "  Median distance: 142.40 m\n",
      "  Avg green coverage: 9.48%\n",
      "  Median green coverage: 2.44%\n",
      "  Buurten with 0% coverage: 102\n",
      "  Buurten with >50% coverage: 22\n",
      "\n",
      "2024:\n",
      "  Avg distance to green: 163.31 m\n",
      "  Median distance: 130.00 m\n",
      "  Avg green coverage: 10.02%\n",
      "  Median green coverage: 2.94%\n",
      "  Buurten with 0% coverage: 87\n",
      "  Buurten with >50% coverage: 19\n",
      "\n",
      "============================================================\n",
      "CHANGES FROM 2020 TO 2024\n",
      "============================================================\n",
      "\n",
      "Average distance change: -29.48 m\n",
      "Average coverage change: 0.54%\n",
      "\n",
      "Buurten with largest coverage INCREASE:\n",
      "   BUURTNAAM_2022 STADSDEELNAAM  green_coverage_percent_2020  green_coverage_percent_2024  coverage_change_percent\n",
      " Markengouw-Noord         Noord                        19.68                        68.02                    48.34\n",
      "      Gooise Kant      Zuidoost                         2.02                        25.73                    23.71\n",
      "Hakfort/Huigenbos      Zuidoost                         2.40                        24.93                    22.53\n",
      "           Huntum      Zuidoost                        17.49                        39.72                    22.23\n",
      " K-buurt-Zuidwest      Zuidoost                         0.04                        20.21                    20.17\n",
      "\n",
      "Buurten with largest coverage DECREASE:\n",
      "     BUURTNAAM_2022 STADSDEELNAAM  green_coverage_percent_2020  green_coverage_percent_2024  coverage_change_percent\n",
      "Rembrandtpark-Noord    Nieuw-West                       100.00                        27.38                   -72.62\n",
      " Rembrandtpark-Zuid    Nieuw-West                       100.00                        35.58                   -64.42\n",
      "   Vogelbuurt-Noord         Noord                        80.80                        58.00                   -22.80\n",
      "     Andreasterrein    Nieuw-West                        16.83                         5.41                   -11.42\n",
      "    Elzenhagen-Zuid         Noord                        14.14                         4.35                    -9.79\n",
      "\n",
      "Buurten FURTHEST from green in 2024:\n",
      "    BUURTNAAM_2022 STADSDEELNAAM  distance_to_nearest_green_m_2024  green_coverage_percent_2024\n",
      "   Spuistraat-Zuid       Centrum                            821.49                         0.00\n",
      "    Kalverdriehoek       Centrum                            810.57                         0.00\n",
      "  Spuistraat-Noord       Centrum                            764.40                         0.00\n",
      "         Holysloot         Noord                            743.08                         0.17\n",
      "Felix Meritisbuurt       Centrum                            731.01                         0.00\n",
      "    Begijnhofbuurt       Centrum                            688.69                         0.00\n",
      "      Amerikahaven     Westpoort                            679.77                         0.74\n",
      " Nieuwendijk-Noord       Centrum                            626.40                         0.00\n",
      "  Nieuwe Kerk e.o.       Centrum                            609.73                         0.00\n",
      "  Leliegracht e.o.       Centrum                            601.13                         0.00\n",
      "\n",
      "Buurten with LOWEST green coverage in 2024:\n",
      "    BUURTNAAM_2022 STADSDEELNAAM  green_coverage_percent_2024  distance_to_nearest_green_m_2024\n",
      "       Kop Zeedijk       Centrum                          0.0                            442.07\n",
      "    Oude Kerk e.o.       Centrum                          0.0                            396.30\n",
      "   Burgwallen-Oost       Centrum                          0.0                            189.17\n",
      "          Nes e.o.       Centrum                          0.0                            523.35\n",
      "   BG-terrein e.o.       Centrum                          0.0                            468.50\n",
      "Stationsplein e.o.       Centrum                          0.0                            457.02\n",
      "         Hemelrijk       Centrum                          0.0                            534.94\n",
      " Nieuwendijk-Noord       Centrum                          0.0                            626.40\n",
      "  Spuistraat-Noord       Centrum                          0.0                            764.40\n",
      "  Nieuwe Kerk e.o.       Centrum                          0.0                            609.73\n"
     ]
    }
   ],
   "source": [
    "from shapely import wkt\n",
    "\n",
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "green_df = pd.read_csv('../data/green_areas_clean.csv')\n",
    "buurten_df = pd.read_csv('../data/buurten.csv')\n",
    "\n",
    "print(f\"Green spaces: {len(green_df)} entries\")\n",
    "\n",
    "# DEBUG: Check what source_year values actually are\n",
    "print(\"\\nDEBUG - source_year info:\")\n",
    "print(f\"  Unique values: {green_df['source_year'].unique()}\")\n",
    "print(f\"  Data type: {green_df['source_year'].dtype}\")\n",
    "print(f\"  Sample rows:\")\n",
    "print(green_df[['osm_id', 'name', 'type', 'source_year']].head())\n",
    "\n",
    "# Convert source_year to string for consistency\n",
    "green_df['source_year'] = green_df['source_year'].astype(str)\n",
    "\n",
    "print(f\"\\nAfter conversion:\")\n",
    "print(f\"  2020: {len(green_df[green_df['source_year'] == '2020'])} entries\")\n",
    "print(f\"  2024: {len(green_df[green_df['source_year'] == '2024'])} entries\")\n",
    "print(f\"Buurten: {len(buurten_df)} entries\")\n",
    "\n",
    "# Parse buurt geometry\n",
    "def parse_buurt_geometry(geom_string):\n",
    "    if pd.isna(geom_string):\n",
    "        return None\n",
    "    clean_wkt = geom_string.split(';')[-1]\n",
    "    return wkt.loads(clean_wkt)\n",
    "\n",
    "buurten_df['polygon_geom'] = buurten_df['geometrie'].apply(parse_buurt_geometry)\n",
    "buurten_gdf = gpd.GeoDataFrame(buurten_df, geometry='polygon_geom', crs='EPSG:28992')\n",
    "\n",
    "# Create centroid points for buurten\n",
    "buurten_df['centroid_geom'] = buurten_df.apply(\n",
    "    lambda row: Point(row['longitude'], row['latitude']), axis=1\n",
    ")\n",
    "buurten_centroids_gdf = gpd.GeoDataFrame(buurten_df, geometry='centroid_geom', crs='EPSG:4326')\n",
    "buurten_centroids_rd = buurten_centroids_gdf.to_crs('EPSG:28992')\n",
    "\n",
    "def calculate_metrics_for_year(year):\n",
    "    \"\"\"Calculate green metrics for a specific year\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"CALCULATING METRICS FOR {year}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Filter green spaces for this year\n",
    "    green_year = green_df[green_df['source_year'] == year].copy()\n",
    "    print(f\"Using {len(green_year)} green spaces from {year}\")\n",
    "    \n",
    "    if len(green_year) == 0:\n",
    "        print(f\"ERROR: No green spaces found for year {year}!\")\n",
    "        return None\n",
    "    \n",
    "    # Convert to GeoDataFrame\n",
    "    green_year['geometry'] = green_year['geometry_wkt'].apply(wkt.loads)\n",
    "    green_gdf = gpd.GeoDataFrame(green_year, geometry='geometry', crs='EPSG:4326')\n",
    "    green_gdf_rd = green_gdf.to_crs('EPSG:28992')\n",
    "    \n",
    "    # Create green centroids\n",
    "    green_centroids_gdf = gpd.GeoDataFrame(\n",
    "        green_year[['osm_id', 'name', 'type', 'area_m2']],\n",
    "        geometry=gpd.points_from_xy(green_year['centroid_lon'], green_year['centroid_lat']),\n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "    green_centroids_rd = green_centroids_gdf.to_crs('EPSG:28992')\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for idx in range(len(buurten_gdf)):\n",
    "        if (idx + 1) % 50 == 0:\n",
    "            print(f\"  Processing {idx + 1}/{len(buurten_gdf)}...\")\n",
    "        \n",
    "        buurt_row = buurten_gdf.iloc[idx]\n",
    "        buurt_polygon = buurten_gdf.geometry.iloc[idx]\n",
    "        buurt_centroid = buurten_centroids_rd.geometry.iloc[idx]\n",
    "        \n",
    "        buurt_area = buurt_polygon.area if hasattr(buurt_polygon, 'area') else 0\n",
    "        \n",
    "        # METRIC 1: Distance to nearest green space\n",
    "        distances = green_centroids_rd.geometry.distance(buurt_centroid)\n",
    "        min_distance = distances.min()\n",
    "        nearest_idx = distances.idxmin()\n",
    "        nearest_green = green_centroids_rd.loc[nearest_idx]\n",
    "        \n",
    "        # METRIC 2: Total green area within buurt\n",
    "        intersecting_greens = green_gdf_rd[green_gdf_rd.intersects(buurt_polygon)]\n",
    "        \n",
    "        total_green_area = 0\n",
    "        if len(intersecting_greens) > 0:\n",
    "            for _, green in intersecting_greens.iterrows():\n",
    "                try:\n",
    "                    intersection = green.geometry.intersection(buurt_polygon)\n",
    "                    if not intersection.is_empty:\n",
    "                        total_green_area += intersection.area\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        total_green_area = min(total_green_area, buurt_area)\n",
    "        green_coverage_percent = (total_green_area / buurt_area * 100) if buurt_area > 0 else 0\n",
    "        \n",
    "        result = {\n",
    "            'BUURTCODE_2022': buurt_row['BUURTCODE_2022'],\n",
    "            f'distance_to_nearest_green_m_{year}': round(min_distance, 2),\n",
    "            f'nearest_green_name_{year}': nearest_green['name'] if pd.notna(nearest_green['name']) else 'Unnamed',\n",
    "            f'nearest_green_type_{year}': nearest_green['type'],\n",
    "            f'nearest_green_area_m2_{year}': nearest_green['area_m2'],\n",
    "            f'total_green_area_m2_{year}': round(total_green_area, 2),\n",
    "            f'green_coverage_percent_{year}': round(green_coverage_percent, 2),\n",
    "            f'num_green_spaces_{year}': len(intersecting_greens)\n",
    "        }\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Calculate for both years\n",
    "results_2020 = calculate_metrics_for_year('2020')\n",
    "results_2024 = calculate_metrics_for_year('2024')\n",
    "\n",
    "if results_2020 is None or results_2024 is None:\n",
    "    print(\"\\nERROR: Could not calculate metrics. Check source_year values in green_areas_clean.csv\")\n",
    "else:\n",
    "    # Merge into single dataframe\n",
    "    merged_results = results_2020.merge(results_2024, on='BUURTCODE_2022')\n",
    "    \n",
    "    # Add buurt metadata\n",
    "    buurt_metadata = buurten_df[['BUURTCODE_2022', 'BUURTNAAM_2022', 'WIJKNAAM_2022', 'STADSDEELNAAM']].copy()\n",
    "    final_results = buurt_metadata.merge(merged_results, on='BUURTCODE_2022')\n",
    "    \n",
    "    # Add buurt area\n",
    "    final_results['buurt_area_m2'] = buurten_gdf.geometry.area.round(2).values\n",
    "    \n",
    "    # Calculate changes\n",
    "    final_results['distance_change_m'] = final_results['distance_to_nearest_green_m_2024'] - final_results['distance_to_nearest_green_m_2020']\n",
    "    final_results['coverage_change_percent'] = final_results['green_coverage_percent_2024'] - final_results['green_coverage_percent_2020']\n",
    "    \n",
    "    # Reorder columns\n",
    "    column_order = [\n",
    "        'BUURTCODE_2022', 'BUURTNAAM_2022', 'WIJKNAAM_2022', 'STADSDEELNAAM', 'buurt_area_m2',\n",
    "        'distance_to_nearest_green_m_2020', 'distance_to_nearest_green_m_2024', 'distance_change_m',\n",
    "        'nearest_green_name_2020', 'nearest_green_type_2020', 'nearest_green_area_m2_2020',\n",
    "        'nearest_green_name_2024', 'nearest_green_type_2024', 'nearest_green_area_m2_2024',\n",
    "        'total_green_area_m2_2020', 'total_green_area_m2_2024',\n",
    "        'green_coverage_percent_2020', 'green_coverage_percent_2024', 'coverage_change_percent',\n",
    "        'num_green_spaces_2020', 'num_green_spaces_2024'\n",
    "    ]\n",
    "    final_results = final_results[column_order]\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = '../data/buurt_green_metrics.csv'\n",
    "    final_results.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"\\n✓ Saved results to {output_file}\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for year in ['2020', '2024']:\n",
    "        print(f\"\\n{year}:\")\n",
    "        print(f\"  Avg distance to green: {final_results[f'distance_to_nearest_green_m_{year}'].mean():.2f} m\")\n",
    "        print(f\"  Median distance: {final_results[f'distance_to_nearest_green_m_{year}'].median():.2f} m\")\n",
    "        print(f\"  Avg green coverage: {final_results[f'green_coverage_percent_{year}'].mean():.2f}%\")\n",
    "        print(f\"  Median green coverage: {final_results[f'green_coverage_percent_{year}'].median():.2f}%\")\n",
    "        print(f\"  Buurten with 0% coverage: {(final_results[f'green_coverage_percent_{year}'] == 0).sum()}\")\n",
    "        print(f\"  Buurten with >50% coverage: {(final_results[f'green_coverage_percent_{year}'] > 50).sum()}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"CHANGES FROM 2020 TO 2024\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nAverage distance change: {final_results['distance_change_m'].mean():.2f} m\")\n",
    "    print(f\"Average coverage change: {final_results['coverage_change_percent'].mean():.2f}%\")\n",
    "    \n",
    "    print(f\"\\nBuurten with largest coverage INCREASE:\")\n",
    "    print(final_results.nlargest(5, 'coverage_change_percent')[\n",
    "        ['BUURTNAAM_2022', 'STADSDEELNAAM', 'green_coverage_percent_2020', 'green_coverage_percent_2024', 'coverage_change_percent']\n",
    "    ].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nBuurten with largest coverage DECREASE:\")\n",
    "    print(final_results.nsmallest(5, 'coverage_change_percent')[\n",
    "        ['BUURTNAAM_2022', 'STADSDEELNAAM', 'green_coverage_percent_2020', 'green_coverage_percent_2024', 'coverage_change_percent']\n",
    "    ].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nBuurten FURTHEST from green in 2024:\")\n",
    "    print(final_results.nlargest(10, 'distance_to_nearest_green_m_2024')[\n",
    "        ['BUURTNAAM_2022', 'STADSDEELNAAM', 'distance_to_nearest_green_m_2024', 'green_coverage_percent_2024']\n",
    "    ].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nBuurten with LOWEST green coverage in 2024:\")\n",
    "    print(final_results.nsmallest(10, 'green_coverage_percent_2024')[\n",
    "        ['BUURTNAAM_2022', 'STADSDEELNAAM', 'green_coverage_percent_2024', 'distance_to_nearest_green_m_2024']\n",
    "    ].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d044a666",
   "metadata": {},
   "source": [
    "### preparing socio economic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf6dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: Loading CSV files\n",
      "============================================================\n",
      "2024 file: 628 rows, 23 columns\n",
      "2023 file: 628 rows, 11 columns\n",
      "2020 file: 579 rows, 23 columns\n",
      "\n",
      "============================================================\n",
      "STEP 2: Cleaning whitespace and quotes from columns 2 and 3\n",
      "============================================================\n",
      "✓ Cleaned columns 2 and 3 in all files\n",
      "\n",
      "Sample column names:\n",
      "  df_2024 col 2: 'Municipality_Name'\n",
      "  df_2023 col 2: 'Municipality_Name'\n",
      "  df_2020 col 2: 'Municipality_Name'\n",
      "\n",
      "============================================================\n",
      "STEP 3: Merging 2023 income data into 2024 file\n",
      "============================================================\n",
      "Columns to merge from 2023 income file: 8\n",
      "Sample columns: ['Higher_Education_Count', 'Avg_Income_Per_Income_Recipient_1000EUR', 'Avg_Income_Per_Inhabitant_1000EUR']\n",
      "✓ Merged 8 columns from 2023 into 2024\n",
      "2024 file now has 23 columns\n",
      "\n",
      "============================================================\n",
      "STEP 4: Translating Dutch headers to English\n",
      "============================================================\n",
      "✓ Translated column names\n",
      "\n",
      "Sample translations:\n",
      "  Original: Population_Total\n",
      "  Translated: Population_Total\n",
      "\n",
      "============================================================\n",
      "STEP 5: Saving processed files\n",
      "============================================================\n",
      "✓ Saved: Kerncijfers_wijken_en_buurten_2024.csv\n",
      "✓ Saved: Kerncijfers_wijken_en_buurten_2020.csv\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "\n",
      "Processed files:\n",
      "  1. Kerncijfers_wijken_en_buurten_2024.csv\n",
      "     - 628 rows x 23 columns\n",
      "     - Includes 2023 income/education data\n",
      "\n",
      "  2. Kerncijfers_wijken_en_buurten_2020.csv\n",
      "     - 579 rows x 23 columns\n",
      "     - Translated column names\n",
      "\n",
      "Column names (first 10):\n",
      "  1. District_Type\n",
      "  2. Municipality_Name\n",
      "  3. Area_Code\n",
      "  4. Population_Total\n",
      "  5. Pop_Age_0_15\n",
      "  6. Pop_Age_15_25\n",
      "  7. Pop_Age_25_45\n",
      "  8. Pop_Age_45_65\n",
      "  9. Pop_Age_65_Plus\n",
      "  10. Avg_Household_Size\n",
      "\n",
      "✓ All tasks completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STEP 1: Loading CSV files\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load the three CSV files\n",
    "df_2024 = pd.read_csv('../data/Kerncijfers_wijken_en_buurten_2024_without_income_data.csv', sep=';')\n",
    "df_2023 = pd.read_csv('../data/Kerncijfers_wijken_en_buurten_2023_income.csv', sep=';')\n",
    "df_2020 = pd.read_csv('../data/Kerncijfers_wijken_en_buurten_2020.csv', sep=';')\n",
    "\n",
    "print(f\"2024 file: {df_2024.shape[0]} rows, {df_2024.shape[1]} columns\")\n",
    "print(f\"2023 file: {df_2023.shape[0]} rows, {df_2023.shape[1]} columns\")\n",
    "print(f\"2020 file: {df_2020.shape[0]} rows, {df_2020.shape[1]} columns\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: Cleaning whitespace and quotes from columns 2 and 3\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def clean_column(df, col_name):\n",
    "    \"\"\"Remove trailing whitespace and quotes from a column\"\"\"\n",
    "    if col_name in df.columns:\n",
    "        df[col_name] = df[col_name].astype(str).str.strip().str.strip('\"').str.strip(\"'\")\n",
    "    return df\n",
    "\n",
    "# Clean each dataframe using its own column names\n",
    "for df in [df_2024, df_2023, df_2020]:\n",
    "    # Clean columns 1 and 2 (0-indexed)\n",
    "    if len(df.columns) > 1:\n",
    "        clean_column(df, df.columns[1])\n",
    "    if len(df.columns) > 2:\n",
    "        clean_column(df, df.columns[2])\n",
    "\n",
    "print(f\"✓ Cleaned columns 2 and 3 in all files\")\n",
    "print(f\"\\nSample column names:\")\n",
    "print(f\"  df_2024 col 2: '{df_2024.columns[1]}'\")\n",
    "print(f\"  df_2023 col 2: '{df_2023.columns[1]}'\")\n",
    "print(f\"  df_2020 col 2: '{df_2020.columns[1]}'\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: Merging 2023 income data into 2024 file\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Identify columns to merge from 2023 (income and education columns)\n",
    "columns_to_skip = [df_2023.columns[0], df_2023.columns[1], df_2023.columns[2]]  # First 3 columns\n",
    "income_education_cols = [col for col in df_2023.columns if col not in columns_to_skip]\n",
    "\n",
    "print(f\"Columns to merge from 2023 income file: {len(income_education_cols)}\")\n",
    "print(f\"Sample columns: {income_education_cols[:3]}\")\n",
    "\n",
    "# Merge data based on encoding column (3rd column)\n",
    "encoding_col = df_2024.columns[2]\n",
    "\n",
    "# Create a mapping from 2023 data\n",
    "for col in income_education_cols:\n",
    "    # Create dictionary mapping encoding to values\n",
    "    value_map = dict(zip(df_2023[encoding_col], df_2023[col]))\n",
    "    \n",
    "    # If column exists in 2024, overwrite it; otherwise create it\n",
    "    if col in df_2024.columns:\n",
    "        df_2024[col] = df_2024[encoding_col].map(value_map)\n",
    "    else:\n",
    "        df_2024.insert(len(df_2024.columns), col, df_2024[encoding_col].map(value_map))\n",
    "\n",
    "print(f\"✓ Merged {len(income_education_cols)} columns from 2023 into 2024\")\n",
    "print(f\"2024 file now has {df_2024.shape[1]} columns\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 4: Translating Dutch headers to English\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Translation dictionary\n",
    "translation_dict = {\n",
    "    \"Wijken en buurten\": \"District_Type\",\n",
    "    \"Regioaanduiding/Gemeentenaam (naam)\": \"Municipality_Name\",\n",
    "    \"Regioaanduiding/Codering (code)\": \"Area_Code\",\n",
    "    \"Bevolking/Aantal inwoners (aantal)\": \"Population_Total\",\n",
    "    \"Bevolking/Leeftijdsgroepen/0 tot 15 jaar (aantal)\": \"Pop_Age_0_15\",\n",
    "    \"Bevolking/Leeftijdsgroepen/15 tot 25 jaar (aantal)\": \"Pop_Age_15_25\",\n",
    "    \"Bevolking/Leeftijdsgroepen/25 tot 45 jaar (aantal)\": \"Pop_Age_25_45\",\n",
    "    \"Bevolking/Leeftijdsgroepen/45 tot 65 jaar (aantal)\": \"Pop_Age_45_65\",\n",
    "    \"Bevolking/Leeftijdsgroepen/65 jaar of ouder (aantal)\": \"Pop_Age_65_Plus\",\n",
    "    \"Bevolking/Particuliere huishoudens/Gemiddelde huishoudensgrootte (aantal)\": \"Avg_Household_Size\",\n",
    "    \"Wonen/Gemiddelde WOZ-waarde van woningen (x 1 000 euro)\": \"Avg_Property_Value_1000EUR\",\n",
    "    \"Wonen/Woningen naar bewoning/Percentage onbewoond (%)\": \"Pct_Unoccupied_Homes\",\n",
    "    \"Wonen/Woningen naar eigendom/Koopwoningen (%)\": \"Pct_Owner_Occupied\",\n",
    "    \"Wonen/Woningen naar eigendom/Huurwoningen/Huurwoningen totaal (%)\": \"Pct_Rental\",\n",
    "    \"Wonen en vastgoed/Gemiddelde WOZ-waarde van woningen (x 1 000 euro)\": \"Avg_Property_Value_1000EUR\",\n",
    "    \"Wonen en vastgoed/Onbewoonde woningen (%)\": \"Pct_Unoccupied_Homes\",\n",
    "    \"Wonen en vastgoed/Woningen naar eigendom/Koopwoningen (%)\": \"Pct_Owner_Occupied\",\n",
    "    \"Wonen en vastgoed/Woningen naar eigendom/Huurwoningen/Huurwoningen totaal (%)\": \"Pct_Rental\",\n",
    "    \"Opleidingsniveau/Opleidingsniveau hoog  (aantal)\": \"Higher_Education_Count\",\n",
    "    \"Onderwijs/Hoogst behaald onderwijsniveau/Hbo, wo (aantal)\": \"Higher_Education_Count\",\n",
    "    \"Inkomen/Inkomen van personen/Gemiddeld inkomen per inkomensontvanger  (x 1 000 euro)\": \"Avg_Income_Per_Earner_1000EUR\",\n",
    "    \"Inkomen/Inkomen van personen/Gemiddeld inkomen per inwoner  (x 1 000 euro)\": \"Avg_Income_Per_Resident_1000EUR\",\n",
    "    \"Inkomen/Inkomen van huishoudens/Gem. gestandaardiseerd inkomen van huish (x 1 000 euro)\": \"Avg_Std_Household_Income_1000EUR\",\n",
    "    \"Inkomen/Inkomen van huishoudens/40% huishoudens met laagste inkomen (%)\": \"Pct_Lowest_40Pct_Income\",\n",
    "    \"Inkomen/Inkomen van huishoudens/20% huishoudens met hoogste inkomen (%)\": \"Pct_Highest_20Pct_Income\",\n",
    "    \"Inkomen/Inkomen van huishoudens/Huishoudens met een laag inkomen (%)\": \"Pct_Low_Income_Households\",\n",
    "    \"Inkomen/Inkomen van huishoudens/Huishoudens tot 120% van sociaal minimum (%)\": \"Pct_Below_120Pct_Social_Min\",\n",
    "    \"Stedelijkheid/Mate van stedelijkheid (code)\": \"Urbanization_Level\"\n",
    "}\n",
    "\n",
    "def translate_columns(df, trans_dict):\n",
    "    \"\"\"Translate column names from Dutch to English\"\"\"\n",
    "    new_columns = []\n",
    "    for col in df.columns:\n",
    "        if col in trans_dict:\n",
    "            new_columns.append(trans_dict[col])\n",
    "        else:\n",
    "            # Keep original if no translation found\n",
    "            new_columns.append(col)\n",
    "    df.columns = new_columns\n",
    "    return df\n",
    "\n",
    "df_2024_translated = translate_columns(df_2024.copy(), translation_dict)\n",
    "df_2020_translated = translate_columns(df_2020.copy(), translation_dict)\n",
    "\n",
    "print(\"✓ Translated column names\")\n",
    "print(f\"\\nSample translations:\")\n",
    "print(f\"  Original: {df_2024.columns[3]}\")\n",
    "print(f\"  Translated: {df_2024_translated.columns[3]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 5: Saving processed files\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save 2024 file with new name (removing \"without_income_data\")\n",
    "output_2024 = '../data/Kerncijfers_wijken_en_buurten_2024.csv'\n",
    "df_2024_translated.to_csv(output_2024, index=False, sep=';')\n",
    "print(f\"✓ Saved: {output_2024}\")\n",
    "\n",
    "# Save 2020 file with translated headers\n",
    "output_2020 = '../data/Kerncijfers_wijken_en_buurten_2020.csv'\n",
    "df_2020_translated.to_csv(output_2020, index=False, sep=';')\n",
    "print(f\"✓ Saved: {output_2020}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nProcessed files:\")\n",
    "print(f\"  1. {output_2024}\")\n",
    "print(f\"     - {df_2024_translated.shape[0]} rows x {df_2024_translated.shape[1]} columns\")\n",
    "print(f\"     - Includes 2023 income/education data\")\n",
    "print(f\"\\n  2. {output_2020}\")\n",
    "print(f\"     - {df_2020_translated.shape[0]} rows x {df_2020_translated.shape[1]} columns\")\n",
    "print(f\"     - Translated column names\")\n",
    "\n",
    "print(f\"\\nColumn names (first 10):\")\n",
    "for i, col in enumerate(df_2024_translated.columns[:10]):\n",
    "    print(f\"  {i+1}. {col}\")\n",
    "\n",
    "print(\"\\n✓ All tasks completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d94b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 6: Filling missing buurt income data with wijk values\n",
      "============================================================\n",
      "\n",
      "Processing 2024 file...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Missing values BEFORE filling (2024):\n",
      "  Avg_Income_Per_Income_Recipient_1000EUR: 433\n",
      "  Avg_Income_Per_Inhabitant_1000EUR: 384\n",
      "  Avg_Std_Household_Income_1000EUR: 526\n",
      "  Pct_Lowest_40Pct_Income: 98\n",
      "  Pct_Highest_20Pct_Income: 98\n",
      "  Pct_Low_Income_Households: 105\n",
      "  Pct_Below_120Pct_Social_Min: 105\n",
      "\n",
      "Values filled from wijk data (2024):\n",
      "  Avg_Income_Per_Income_Recipient_1000EUR: 357 buurten filled\n",
      "  Avg_Income_Per_Inhabitant_1000EUR: 308 buurten filled\n",
      "  Avg_Std_Household_Income_1000EUR: 410 buurten filled\n",
      "  Pct_Lowest_40Pct_Income: 91 buurten filled\n",
      "  Pct_Highest_20Pct_Income: 91 buurten filled\n",
      "  Pct_Low_Income_Households: 89 buurten filled\n",
      "  Pct_Below_120Pct_Social_Min: 89 buurten filled\n",
      "\n",
      "Missing values AFTER filling (2024):\n",
      "  Avg_Income_Per_Income_Recipient_1000EUR: 76\n",
      "  Avg_Income_Per_Inhabitant_1000EUR: 76\n",
      "  Avg_Std_Household_Income_1000EUR: 116\n",
      "  Pct_Lowest_40Pct_Income: 7\n",
      "  Pct_Highest_20Pct_Income: 7\n",
      "  Pct_Low_Income_Households: 16\n",
      "  Pct_Below_120Pct_Social_Min: 16\n",
      "\n",
      "------------------------------------------------------------\n",
      "Processing 2020 file...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Missing values BEFORE filling (2020):\n",
      "  Avg_Income_Per_Income_Recipient_1000EUR: 80\n",
      "  Avg_Income_Per_Inhabitant_1000EUR: 77\n",
      "  Avg_Std_Household_Income_1000EUR: 95\n",
      "  Pct_Lowest_40Pct_Income: 91\n",
      "  Pct_Highest_20Pct_Income: 91\n",
      "  Pct_Low_Income_Households: 93\n",
      "  Pct_Below_120Pct_Social_Min: 93\n",
      "\n",
      "Values filled from wijk data (2020):\n",
      "  Avg_Income_Per_Income_Recipient_1000EUR: 58 buurten filled\n",
      "  Avg_Income_Per_Inhabitant_1000EUR: 64 buurten filled\n",
      "  Avg_Std_Household_Income_1000EUR: 73 buurten filled\n",
      "  Pct_Lowest_40Pct_Income: 76 buurten filled\n",
      "  Pct_Highest_20Pct_Income: 76 buurten filled\n",
      "  Pct_Low_Income_Households: 78 buurten filled\n",
      "  Pct_Below_120Pct_Social_Min: 78 buurten filled\n",
      "\n",
      "Missing values AFTER filling (2020):\n",
      "  Avg_Income_Per_Income_Recipient_1000EUR: 22\n",
      "  Avg_Income_Per_Inhabitant_1000EUR: 13\n",
      "  Avg_Std_Household_Income_1000EUR: 22\n",
      "  Pct_Lowest_40Pct_Income: 15\n",
      "  Pct_Highest_20Pct_Income: 15\n",
      "  Pct_Low_Income_Households: 15\n",
      "  Pct_Below_120Pct_Social_Min: 15\n",
      "\n",
      "============================================================\n",
      "STEP 7: Saving updated files\n",
      "============================================================\n",
      "✓ Updated and saved: Kerncijfers_wijken_en_buurten_2024.csv\n",
      "✓ Updated and saved: Kerncijfers_wijken_en_buurten_2020.csv\n",
      "\n",
      "============================================================\n",
      "SUMMARY OF INCOME DATA FILLING\n",
      "============================================================\n",
      "\n",
      "2024 file:\n",
      "\n",
      "  Avg_Income_Per_Income_Recipient_1000EUR:\n",
      "    Missing before: 433\n",
      "    Filled with wijk: 357\n",
      "    Still missing: 76\n",
      "    Improvement: 357 fewer missing values\n",
      "\n",
      "  Avg_Income_Per_Inhabitant_1000EUR:\n",
      "    Missing before: 384\n",
      "    Filled with wijk: 308\n",
      "    Still missing: 76\n",
      "    Improvement: 308 fewer missing values\n",
      "\n",
      "  Avg_Std_Household_Income_1000EUR:\n",
      "    Missing before: 526\n",
      "    Filled with wijk: 410\n",
      "    Still missing: 116\n",
      "    Improvement: 410 fewer missing values\n",
      "\n",
      "  Pct_Lowest_40Pct_Income:\n",
      "    Missing before: 98\n",
      "    Filled with wijk: 91\n",
      "    Still missing: 7\n",
      "    Improvement: 91 fewer missing values\n",
      "\n",
      "  Pct_Highest_20Pct_Income:\n",
      "    Missing before: 98\n",
      "    Filled with wijk: 91\n",
      "    Still missing: 7\n",
      "    Improvement: 91 fewer missing values\n",
      "\n",
      "  Pct_Low_Income_Households:\n",
      "    Missing before: 105\n",
      "    Filled with wijk: 89\n",
      "    Still missing: 16\n",
      "    Improvement: 89 fewer missing values\n",
      "\n",
      "  Pct_Below_120Pct_Social_Min:\n",
      "    Missing before: 105\n",
      "    Filled with wijk: 89\n",
      "    Still missing: 16\n",
      "    Improvement: 89 fewer missing values\n",
      "\n",
      "2020 file:\n",
      "\n",
      "  Avg_Income_Per_Income_Recipient_1000EUR:\n",
      "    Missing before: 80\n",
      "    Filled with wijk: 58\n",
      "    Still missing: 22\n",
      "    Improvement: 58 fewer missing values\n",
      "\n",
      "  Avg_Income_Per_Inhabitant_1000EUR:\n",
      "    Missing before: 77\n",
      "    Filled with wijk: 64\n",
      "    Still missing: 13\n",
      "    Improvement: 64 fewer missing values\n",
      "\n",
      "  Avg_Std_Household_Income_1000EUR:\n",
      "    Missing before: 95\n",
      "    Filled with wijk: 73\n",
      "    Still missing: 22\n",
      "    Improvement: 73 fewer missing values\n",
      "\n",
      "  Pct_Lowest_40Pct_Income:\n",
      "    Missing before: 91\n",
      "    Filled with wijk: 76\n",
      "    Still missing: 15\n",
      "    Improvement: 76 fewer missing values\n",
      "\n",
      "  Pct_Highest_20Pct_Income:\n",
      "    Missing before: 91\n",
      "    Filled with wijk: 76\n",
      "    Still missing: 15\n",
      "    Improvement: 76 fewer missing values\n",
      "\n",
      "  Pct_Low_Income_Households:\n",
      "    Missing before: 93\n",
      "    Filled with wijk: 78\n",
      "    Still missing: 15\n",
      "    Improvement: 78 fewer missing values\n",
      "\n",
      "  Pct_Below_120Pct_Social_Min:\n",
      "    Missing before: 93\n",
      "    Filled with wijk: 78\n",
      "    Still missing: 15\n",
      "    Improvement: 78 fewer missing values\n",
      "\n",
      "✓ Income data filling completed!\n",
      "\n",
      "Note: Remaining missing values are buurten where even the wijk has no data.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 6: Filling missing buurt income data with wijk values\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def extract_wijk_code(area_code):\n",
    "    \"\"\"\n",
    "    Extract wijk code from buurt code.\n",
    "    BU03630300 -> WK036303\n",
    "    WK036303 -> WK036303 (already a wijk)\n",
    "    \"\"\"\n",
    "    if pd.isna(area_code):\n",
    "        return None\n",
    "    area_code = str(area_code).strip()\n",
    "    if area_code.startswith('WK'):\n",
    "        return area_code\n",
    "    elif area_code.startswith('BU') and len(area_code) >= 8:\n",
    "        # BU03630300 -> WK036303 (first 8 characters, replace BU with WK)\n",
    "        return 'WK' + area_code[2:8]\n",
    "    return None\n",
    "\n",
    "def fill_buurt_with_wijk_income(df, income_columns):\n",
    "    \"\"\"\n",
    "    Fill missing buurt income values with their wijk values if available.\n",
    "    \"\"\"\n",
    "    # Create wijk code column\n",
    "    df['wijk_code'] = df['Area_Code'].apply(extract_wijk_code)\n",
    "    \n",
    "    # Create dictionary mapping wijk codes to their income values\n",
    "    wijk_data = df[df['Area_Code'].str.startswith('WK', na=False)].copy()\n",
    "    \n",
    "    filled_count = {col: 0 for col in income_columns}\n",
    "    \n",
    "    for col in income_columns:\n",
    "        # Create mapping: wijk_code -> income_value\n",
    "        wijk_income_map = dict(zip(wijk_data['Area_Code'], wijk_data[col]))\n",
    "        \n",
    "        # For each row (buurt), if income is missing, try to fill with wijk value\n",
    "        for idx, row in df.iterrows():\n",
    "            if pd.isna(row[col]) or row[col] == '' or row[col] == '.':\n",
    "                wijk_code = row['wijk_code']\n",
    "                if wijk_code and wijk_code in wijk_income_map:\n",
    "                    wijk_value = wijk_income_map[wijk_code]\n",
    "                    if pd.notna(wijk_value) and wijk_value != '' and wijk_value != '.':\n",
    "                        df.at[idx, col] = wijk_value\n",
    "                        filled_count[col] += 1\n",
    "    \n",
    "    # Drop temporary wijk_code column\n",
    "    df = df.drop(columns=['wijk_code'])\n",
    "    \n",
    "    return df, filled_count\n",
    "\n",
    "# Income columns to fill\n",
    "income_columns = [\n",
    "    'Avg_Income_Per_Income_Recipient_1000EUR',\n",
    "    'Avg_Income_Per_Inhabitant_1000EUR', \n",
    "    'Avg_Std_Household_Income_1000EUR',\n",
    "    'Pct_Lowest_40Pct_Income',\n",
    "    'Pct_Highest_20Pct_Income',\n",
    "    'Pct_Low_Income_Households',\n",
    "    'Pct_Below_120Pct_Social_Min',\n",
    "]\n",
    "\n",
    "print(\"\\nProcessing 2024 file...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Check missing values before\n",
    "missing_before_2024 = {}\n",
    "for col in income_columns:\n",
    "    missing_before_2024[col] = df_2024_translated[col].isna().sum()\n",
    "\n",
    "print(f\"\\nMissing values BEFORE filling (2024):\")\n",
    "for col, count in missing_before_2024.items():\n",
    "    print(f\"  {col}: {count}\")\n",
    "\n",
    "# Fill missing values\n",
    "df_2024_filled, filled_2024 = fill_buurt_with_wijk_income(df_2024_translated.copy(), income_columns)\n",
    "\n",
    "print(f\"\\nValues filled from wijk data (2024):\")\n",
    "for col, count in filled_2024.items():\n",
    "    print(f\"  {col}: {count} buurten filled\")\n",
    "\n",
    "# Check missing values after\n",
    "missing_after_2024 = {}\n",
    "for col in income_columns:\n",
    "    missing_after_2024[col] = df_2024_filled[col].isna().sum()\n",
    "\n",
    "print(f\"\\nMissing values AFTER filling (2024):\")\n",
    "for col, count in missing_after_2024.items():\n",
    "    print(f\"  {col}: {count}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Processing 2020 file...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Check missing values before\n",
    "missing_before_2020 = {}\n",
    "for col in income_columns:\n",
    "    missing_before_2020[col] = df_2020_translated[col].isna().sum()\n",
    "\n",
    "print(f\"\\nMissing values BEFORE filling (2020):\")\n",
    "for col, count in missing_before_2020.items():\n",
    "    print(f\"  {col}: {count}\")\n",
    "\n",
    "# Fill missing values\n",
    "df_2020_filled, filled_2020 = fill_buurt_with_wijk_income(df_2020_translated.copy(), income_columns)\n",
    "\n",
    "print(f\"\\nValues filled from wijk data (2020):\")\n",
    "for col, count in filled_2020.items():\n",
    "    print(f\"  {col}: {count} buurten filled\")\n",
    "\n",
    "# Check missing values after\n",
    "missing_after_2020 = {}\n",
    "for col in income_columns:\n",
    "    missing_after_2020[col] = df_2020_filled[col].isna().sum()\n",
    "\n",
    "print(f\"\\nMissing values AFTER filling (2020):\")\n",
    "for col, count in missing_after_2020.items():\n",
    "    print(f\"  {col}: {count}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 7: Saving updated files\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save updated files\n",
    "df_2024_filled.to_csv('../data/Kerncijfers_wijken_en_buurten_2024.csv', index=False, sep=';')\n",
    "print(f\"✓ Updated and saved: Kerncijfers_wijken_en_buurten_2024.csv\")\n",
    "\n",
    "df_2020_filled.to_csv('../data/Kerncijfers_wijken_en_buurten_2020.csv', index=False, sep=';')\n",
    "print(f\"✓ Updated and saved: Kerncijfers_wijken_en_buurten_2020.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY OF INCOME DATA FILLING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n2024 file:\")\n",
    "for col in income_columns:\n",
    "    before = missing_before_2024[col]\n",
    "    filled = filled_2024[col]\n",
    "    after = missing_after_2024[col]\n",
    "    print(f\"\\n  {col}:\")\n",
    "    print(f\"    Missing before: {before}\")\n",
    "    print(f\"    Filled with wijk: {filled}\")\n",
    "    print(f\"    Still missing: {after}\")\n",
    "    print(f\"    Improvement: {before - after} fewer missing values\")\n",
    "\n",
    "print(\"\\n2020 file:\")\n",
    "for col in income_columns:\n",
    "    before = missing_before_2020[col]\n",
    "    filled = filled_2020[col]\n",
    "    after = missing_after_2020[col]\n",
    "    print(f\"\\n  {col}:\")\n",
    "    print(f\"    Missing before: {before}\")\n",
    "    print(f\"    Filled with wijk: {filled}\")\n",
    "    print(f\"    Still missing: {after}\")\n",
    "    print(f\"    Improvement: {before - after} fewer missing values\")\n",
    "\n",
    "print(\"\\n✓ Income data filling completed!\")\n",
    "print(\"\\nNote: Remaining missing values are buurten where even the wijk has no data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e838cf9f",
   "metadata": {},
   "source": [
    "### cleaning datasets (only keep valid buurten entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1238b42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reference file: buurten.csv\n",
      "Found 439 valid 2015 CBS buurt codes\n",
      "Found 439 valid 2022 CBS buurt codes\n",
      "Total unique valid CBS codes: 878\n",
      "\n",
      "Found 439 valid 2015 regular buurt codes\n",
      "Found 439 valid 2022 regular buurt codes\n",
      "Total unique valid regular codes: 878\n",
      "\n",
      "Sample CBS codes: ['BU0363AF09', 'BU03636100', 'BU03635806', 'BU0363KD05', 'BU0363AH04']\n",
      "Sample regular codes: ['ME03', 'A04h', 'FQ10', 'KM01', 'NG03']\n",
      "\n",
      "============================================================\n",
      "Processing: buurt_green_metrics.csv\n",
      "============================================================\n",
      "Original rows: 439\n",
      "File year: 2022\n",
      "Using: regular buurt codes\n",
      "Filtered rows: 439\n",
      "Removed rows: 0\n",
      "✓ Saved filtered data to: filtered_buurt_green_metrics.csv\n",
      "\n",
      "Code distribution:\n",
      "  Matches 2015 codes: 0\n",
      "  Matches 2022 codes: 439\n",
      "\n",
      "============================================================\n",
      "Processing: Kerncijfers_wijken_en_buurten_2020.csv\n",
      "============================================================\n",
      "Original rows: 579\n",
      "File year: 2020\n",
      "Using: CBS buurt codes\n",
      "Filtered rows: 439\n",
      "Removed rows: 140\n",
      "\n",
      "Sample removed codes (first 10):\n",
      "  - WK036364 [Wijk (WK)]\n",
      "  - WK036338 [Wijk (WK)]\n",
      "  - WK036325 [Wijk (WK)]\n",
      "  - WK036307 [Wijk (WK)]\n",
      "  - WK036351 [Wijk (WK)]\n",
      "  - WK036333 [Wijk (WK)]\n",
      "  - WK036378 [Wijk (WK)]\n",
      "  - WK036310 [Wijk (WK)]\n",
      "  - BU03635000 [Buurt (BU) - but not in reference]\n",
      "  - WK036376 [Wijk (WK)]\n",
      "✓ Saved filtered data to: filtered_Kerncijfers_wijken_en_buurten_2020.csv\n",
      "\n",
      "Code distribution:\n",
      "  Matches 2015 codes: 439\n",
      "  Matches 2022 codes: 0\n",
      "\n",
      "============================================================\n",
      "Processing: Kerncijfers_wijken_en_buurten_2024.csv\n",
      "============================================================\n",
      "Original rows: 628\n",
      "File year: 2024\n",
      "Using: CBS buurt codes\n",
      "Filtered rows: 439\n",
      "Removed rows: 189\n",
      "\n",
      "Sample removed codes (first 10):\n",
      "  - WK0363EQ [Wijk (WK)]\n",
      "  - WK0363KM [Wijk (WK)]\n",
      "  - WK0363KF [Wijk (WK)]\n",
      "  - BU0363EB03 [Buurt (BU) - but not in reference]\n",
      "  - WK0363SE [Wijk (WK)]\n",
      "  - BU0363EA01 [Buurt (BU) - but not in reference]\n",
      "  - WK0363NB [Wijk (WK)]\n",
      "  - BU0363FD03 [Buurt (BU) - but not in reference]\n",
      "  - WK0363NN [Wijk (WK)]\n",
      "  - BU0363SB03 [Buurt (BU) - but not in reference]\n",
      "✓ Saved filtered data to: filtered_Kerncijfers_wijken_en_buurten_2024.csv\n",
      "\n",
      "Code distribution:\n",
      "  Matches 2015 codes: 0\n",
      "  Matches 2022 codes: 439\n",
      "\n",
      "============================================================\n",
      "Processing: proximity_to_facilities_2020.csv\n",
      "============================================================\n",
      "Original rows: 579\n",
      "File year: 2020\n",
      "Using: CBS buurt codes\n",
      "Filtered rows: 439\n",
      "Removed rows: 140\n",
      "\n",
      "Sample removed codes (first 10):\n",
      "  - WK036364 [Wijk (WK)]\n",
      "  - WK036338 [Wijk (WK)]\n",
      "  - WK036325 [Wijk (WK)]\n",
      "  - WK036307 [Wijk (WK)]\n",
      "  - WK036351 [Wijk (WK)]\n",
      "  - WK036333 [Wijk (WK)]\n",
      "  - WK036378 [Wijk (WK)]\n",
      "  - WK036310 [Wijk (WK)]\n",
      "  - BU03635000 [Buurt (BU) - but not in reference]\n",
      "  - WK036376 [Wijk (WK)]\n",
      "✓ Saved filtered data to: filtered_proximity_to_facilities_2020.csv\n",
      "\n",
      "Code distribution:\n",
      "  Matches 2015 codes: 439\n",
      "  Matches 2022 codes: 0\n",
      "\n",
      "============================================================\n",
      "Processing: proximity_to_facilities_2024.csv\n",
      "============================================================\n",
      "Original rows: 628\n",
      "File year: 2024\n",
      "Using: CBS buurt codes\n",
      "Filtered rows: 439\n",
      "Removed rows: 189\n",
      "\n",
      "Sample removed codes (first 10):\n",
      "  - WK0363EQ [Wijk (WK)]\n",
      "  - WK0363KM [Wijk (WK)]\n",
      "  - WK0363KF [Wijk (WK)]\n",
      "  - BU0363EB03 [Buurt (BU) - but not in reference]\n",
      "  - WK0363SE [Wijk (WK)]\n",
      "  - BU0363EA01 [Buurt (BU) - but not in reference]\n",
      "  - WK0363NB [Wijk (WK)]\n",
      "  - BU0363FD03 [Buurt (BU) - but not in reference]\n",
      "  - WK0363NN [Wijk (WK)]\n",
      "  - BU0363SB03 [Buurt (BU) - but not in reference]\n",
      "✓ Saved filtered data to: filtered_proximity_to_facilities_2024.csv\n",
      "\n",
      "Code distribution:\n",
      "  Matches 2015 codes: 0\n",
      "  Matches 2022 codes: 439\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "\n",
      "                                  File  Year           Code_Type  Original  Filtered  Removed Percentage_Kept\n",
      "               buurt_green_metrics.csv  2022 regular buurt codes       439       439        0          100.0%\n",
      "Kerncijfers_wijken_en_buurten_2020.csv  2020     CBS buurt codes       579       439      140           75.8%\n",
      "Kerncijfers_wijken_en_buurten_2024.csv  2024     CBS buurt codes       628       439      189           69.9%\n",
      "      proximity_to_facilities_2020.csv  2020     CBS buurt codes       579       439      140           75.8%\n",
      "      proximity_to_facilities_2024.csv  2024     CBS buurt codes       628       439      189           69.9%\n",
      "\n",
      "============================================================\n",
      "VALIDATION\n",
      "============================================================\n",
      "\n",
      "Checking code consistency across files...\n",
      "\n",
      "Unique buurten in each file:\n",
      "  buurt_green_metrics: 439 (using regular codes)\n",
      "  Kerncijfers 2020: 439 (using CBS codes)\n",
      "  Kerncijfers 2024: 439 (using CBS codes)\n",
      "\n",
      "Kerncijfers 2020 codes:\n",
      "  Using 2015 CBS system: 439 codes\n",
      "  Using 2022 CBS system: 0 codes\n",
      "\n",
      "Kerncijfers 2024 codes:\n",
      "  Using 2015 CBS system: 0 codes\n",
      "  Using 2022 CBS system: 439 codes\n",
      "\n",
      "Green metrics codes:\n",
      "  Using 2015 regular system: 0 codes\n",
      "  Using 2022 regular system: 439 codes\n",
      "\n",
      "✓ All files have been filtered and saved with 'filtered_' prefix\n"
     ]
    }
   ],
   "source": [
    "# Load the reference file with valid buurten codes\n",
    "print(\"Loading reference file: buurten.csv\")\n",
    "buurten_df = pd.read_csv('../data/buurten.csv')\n",
    "\n",
    "# Get CBS codes (for most files)\n",
    "valid_buurt_codes_2015_cbs = set(buurten_df['BUURTCODE_CBS_2015'].unique())\n",
    "valid_buurt_codes_2022_cbs = set(buurten_df['BUURTCODE_CBS_2022'].unique())\n",
    "all_valid_codes_cbs = valid_buurt_codes_2015_cbs.union(valid_buurt_codes_2022_cbs)\n",
    "\n",
    "# Get regular buurt codes (for buurt_green_metrics.csv)\n",
    "valid_buurt_codes_2015_regular = set(buurten_df['BUURTCODE_2015'].unique())\n",
    "valid_buurt_codes_2022_regular = set(buurten_df['BUURTCODE_2022'].unique())\n",
    "all_valid_codes_regular = valid_buurt_codes_2015_regular.union(valid_buurt_codes_2022_regular)\n",
    "\n",
    "print(f\"Found {len(valid_buurt_codes_2015_cbs)} valid 2015 CBS buurt codes\")\n",
    "print(f\"Found {len(valid_buurt_codes_2022_cbs)} valid 2022 CBS buurt codes\")\n",
    "print(f\"Total unique valid CBS codes: {len(all_valid_codes_cbs)}\")\n",
    "print(f\"\\nFound {len(valid_buurt_codes_2015_regular)} valid 2015 regular buurt codes\")\n",
    "print(f\"Found {len(valid_buurt_codes_2022_regular)} valid 2022 regular buurt codes\")\n",
    "print(f\"Total unique valid regular codes: {len(all_valid_codes_regular)}\")\n",
    "print(f\"\\nSample CBS codes: {list(all_valid_codes_cbs)[:5]}\")\n",
    "print(f\"Sample regular codes: {list(all_valid_codes_regular)[:5]}\")\n",
    "\n",
    "# Define the files to filter\n",
    "files_to_filter = {\n",
    "    '../data/buurt_green_metrics.csv': {\n",
    "        'code_column': 'BUURTCODE_2022',\n",
    "        'separator': ',',\n",
    "        'year': 2022,\n",
    "        'use_regular_codes': True  # Use BUURTCODE columns instead of BUURTCODE_CBS\n",
    "    },\n",
    "    '../data/Kerncijfers_wijken_en_buurten_2020.csv': {\n",
    "        'code_column': 'Area_Code',\n",
    "        'separator': ';',\n",
    "        'year': 2020,\n",
    "        'use_regular_codes': False\n",
    "    },\n",
    "    '../data/Kerncijfers_wijken_en_buurten_2024.csv': {\n",
    "        'code_column': 'Area_Code',\n",
    "        'separator': ';',\n",
    "        'year': 2024,\n",
    "        'use_regular_codes': False\n",
    "    },\n",
    "    '../data/proximity_to_facilities_2020.csv': {\n",
    "        'code_column': 'Encoding',\n",
    "        'separator': ';',\n",
    "        'year': 2020,\n",
    "        'use_regular_codes': False\n",
    "    },\n",
    "    '../data/proximity_to_facilities_2024.csv': {\n",
    "        'code_column': 'Encoding_3',\n",
    "        'separator': ';',\n",
    "        'year': 2024,\n",
    "        'use_regular_codes': False\n",
    "    }\n",
    "}\n",
    "\n",
    "# Process each file\n",
    "summary = []\n",
    "\n",
    "for filename, config in files_to_filter.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {filename}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        # Read file with appropriate separator\n",
    "        df = pd.read_csv(filename, sep=config['separator'])\n",
    "        \n",
    "        original_count = len(df)\n",
    "        code_column = config['code_column']\n",
    "        file_year = config['year']\n",
    "        \n",
    "        # Select appropriate validation codes\n",
    "        if config.get('use_regular_codes', False):\n",
    "            all_valid_codes = all_valid_codes_regular\n",
    "            codes_2015 = valid_buurt_codes_2015_regular\n",
    "            codes_2022 = valid_buurt_codes_2022_regular\n",
    "            code_type_name = \"regular buurt codes\"\n",
    "        else:\n",
    "            all_valid_codes = all_valid_codes_cbs\n",
    "            codes_2015 = valid_buurt_codes_2015_cbs\n",
    "            codes_2022 = valid_buurt_codes_2022_cbs\n",
    "            code_type_name = \"CBS buurt codes\"\n",
    "        \n",
    "        print(f\"Original rows: {original_count}\")\n",
    "        print(f\"File year: {file_year}\")\n",
    "        print(f\"Using: {code_type_name}\")\n",
    "        \n",
    "        # Check if code column exists\n",
    "        if code_column not in df.columns:\n",
    "            print(f\"ERROR: Column '{code_column}' not found!\")\n",
    "            print(f\"Available columns: {df.columns.tolist()}\")\n",
    "            continue\n",
    "        \n",
    "        # Strip whitespace from codes for comparison\n",
    "        df[code_column] = df[code_column].astype(str).str.strip()\n",
    "        \n",
    "        # Filter to only valid buurt codes\n",
    "        filtered_df = df[df[code_column].isin(all_valid_codes)]\n",
    "        \n",
    "        filtered_count = len(filtered_df)\n",
    "        removed_count = original_count - filtered_count\n",
    "        \n",
    "        print(f\"Filtered rows: {filtered_count}\")\n",
    "        print(f\"Removed rows: {removed_count}\")\n",
    "        \n",
    "        if removed_count > 0:\n",
    "            # Show some examples of removed codes\n",
    "            removed_codes = set(df[code_column]) - all_valid_codes\n",
    "            print(f\"\\nSample removed codes (first 10):\")\n",
    "            for code in list(removed_codes)[:10]:\n",
    "                # Check if it's a wijk/gemeente code by looking at pattern\n",
    "                code_type = \"Unknown\"\n",
    "                if code.startswith('GM'):\n",
    "                    code_type = \"Municipality (GM)\"\n",
    "                elif code.startswith('WK'):\n",
    "                    code_type = \"Wijk (WK)\"\n",
    "                elif code.startswith('BU'):\n",
    "                    code_type = \"Buurt (BU) - but not in reference\"\n",
    "                print(f\"  - {code} [{code_type}]\")\n",
    "        \n",
    "        # Save filtered file\n",
    "        base_filename = filename.split('/')[-1] # Get filename without path\n",
    "        output_filename = f\"../data/filtered_{base_filename}\"\n",
    "        filtered_df.to_csv(output_filename, sep=config['separator'], index=False)\n",
    "        \n",
    "        print(f\"✓ Saved filtered data to: {output_filename}\")\n",
    "        \n",
    "        # Additional statistics\n",
    "        if filtered_count > 0:\n",
    "            # Check which code system is being used\n",
    "            codes_in_2015 = filtered_df[code_column].isin(codes_2015).sum()\n",
    "            codes_in_2022 = filtered_df[code_column].isin(codes_2022).sum()\n",
    "            print(f\"\\nCode distribution:\")\n",
    "            print(f\"  Matches 2015 codes: {codes_in_2015}\")\n",
    "            print(f\"  Matches 2022 codes: {codes_in_2022}\")\n",
    "        \n",
    "        summary.append({\n",
    "            'File': filename,\n",
    "            'Year': file_year,\n",
    "            'Code_Type': code_type_name,\n",
    "            'Original': original_count,\n",
    "            'Filtered': filtered_count,\n",
    "            'Removed': removed_count,\n",
    "            'Percentage_Kept': f\"{(filtered_count/original_count*100):.1f}%\"\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR processing {filename}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUMMARY\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"VALIDATION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"\\nChecking code consistency across files...\")\n",
    "\n",
    "# Load filtered files and check overlap\n",
    "try:\n",
    "    green_2020 = pd.read_csv('../data/filtered_buurt_green_metrics.csv')\n",
    "    kern_2020 = pd.read_csv('../data/filtered_Kerncijfers_wijken_en_buurten_2020.csv', sep=';')\n",
    "    kern_2024 = pd.read_csv('../data/filtered_Kerncijfers_wijken_en_buurten_2024.csv', sep=';')\n",
    "    \n",
    "    green_codes = set(green_2020['BUURTCODE_2022'].unique())\n",
    "    kern_2020_codes = set(kern_2020['Area_Code'].unique())\n",
    "    kern_2024_codes = set(kern_2024['Area_Code'].unique())\n",
    "    \n",
    "    print(f\"\\nUnique buurten in each file:\")\n",
    "    print(f\"  buurt_green_metrics: {len(green_codes)} (using regular codes)\")\n",
    "    print(f\"  Kerncijfers 2020: {len(kern_2020_codes)} (using CBS codes)\")\n",
    "    print(f\"  Kerncijfers 2024: {len(kern_2024_codes)} (using CBS codes)\")\n",
    "    \n",
    "    # Check if 2020 codes map to 2015 system\n",
    "    kern_2020_in_2015 = len(kern_2020_codes.intersection(valid_buurt_codes_2015_cbs))\n",
    "    kern_2020_in_2022 = len(kern_2020_codes.intersection(valid_buurt_codes_2022_cbs))\n",
    "    \n",
    "    print(f\"\\nKerncijfers 2020 codes:\")\n",
    "    print(f\"  Using 2015 CBS system: {kern_2020_in_2015} codes\")\n",
    "    print(f\"  Using 2022 CBS system: {kern_2020_in_2022} codes\")\n",
    "    \n",
    "    # Check if 2024 codes map to 2022 system\n",
    "    kern_2024_in_2015 = len(kern_2024_codes.intersection(valid_buurt_codes_2015_cbs))\n",
    "    kern_2024_in_2022 = len(kern_2024_codes.intersection(valid_buurt_codes_2022_cbs))\n",
    "    \n",
    "    print(f\"\\nKerncijfers 2024 codes:\")\n",
    "    print(f\"  Using 2015 CBS system: {kern_2024_in_2015} codes\")\n",
    "    print(f\"  Using 2022 CBS system: {kern_2024_in_2022} codes\")\n",
    "    \n",
    "    # Check green metrics codes\n",
    "    green_in_2015 = len(green_codes.intersection(valid_buurt_codes_2015_regular))\n",
    "    green_in_2022 = len(green_codes.intersection(valid_buurt_codes_2022_regular))\n",
    "    \n",
    "    print(f\"\\nGreen metrics codes:\")\n",
    "    print(f\"  Using 2015 regular system: {green_in_2015} codes\")\n",
    "    print(f\"  Using 2022 regular system: {green_in_2022} codes\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not perform validation: {e}\")\n",
    "\n",
    "print(f\"\\n✓ All files have been filtered and saved with 'filtered_' prefix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a900a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1: Loading all files\n",
      "================================================================================\n",
      "Kern 2020: 439 rows, 23 columns\n",
      "Kern 2024: 439 rows, 23 columns\n",
      "Green: 439 rows, 21 columns\n",
      "Facilities 2020: 439 rows, 12 columns\n",
      "Facilities 2024: 439 rows, 12 columns\n",
      "\n",
      "================================================================================\n",
      "STEP 2: Create mappings\n",
      "================================================================================\n",
      "Mappings created\n",
      "\n",
      "================================================================================\n",
      "STEP 3: Define comprehensive column renaming\n",
      "================================================================================\n",
      "Column renaming dictionaries defined\n",
      "\n",
      "================================================================================\n",
      "STEP 4: Process GREEN METRICS (both years combined)\n",
      "================================================================================\n",
      "Green combined: 439 rows, 19 columns\n",
      "Columns: ['buurtcode_2022', 'buurt_name', 'wijk_name', 'stadsdeel_name', 'buurt_area_m2', 'dist_nearest_green_2020', 'nearest_green_name_2020', 'nearest_green_type_2020', 'nearest_green_area_m2_2020', 'total_green_area_m2_2020', 'green_coverage_pct_2020', 'num_green_spaces_2020', 'dist_nearest_green_2024', 'nearest_green_name_2024', 'nearest_green_type_2024', 'nearest_green_area_m2_2024', 'total_green_area_m2_2024', 'green_coverage_pct_2024', 'num_green_spaces_2024']\n",
      "\n",
      "================================================================================\n",
      "STEP 5: Process 2020 data (ALL COLUMNS)\n",
      "================================================================================\n",
      "K20 columns after rename: 27\n",
      "F20 columns after rename: 13\n",
      "G20 columns selected: 12\n",
      "2020 data: 439 rows, 49 columns\n",
      "\n",
      "================================================================================\n",
      "STEP 6: Process 2024 data (ALL COLUMNS)\n",
      "================================================================================\n",
      "K24 columns after rename: 27\n",
      "F24 columns after rename: 13\n",
      "G24 columns selected: 12\n",
      "2024 data: 439 rows, 49 columns\n",
      "\n",
      "================================================================================\n",
      "STEP 7: Combine to long format\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final: 878 rows\n",
      "Unique buurten: 439\n",
      "Total columns: 56\n",
      "Rows by year:\n",
      "year\n",
      "2020    439\n",
      "2024    439\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "STEP 8: Column inventory\n",
      "================================================================================\n",
      "\n",
      "All columns in final dataset:\n",
      "   1. district_type\n",
      "   2. municipality_name\n",
      "   3. area_code_original\n",
      "   4. population_total\n",
      "   5. pop_age_0_15\n",
      "   6. pop_age_15_25\n",
      "   7. pop_age_25_45\n",
      "   8. pop_age_45_65\n",
      "   9. pop_age_65_plus\n",
      "  10. avg_household_size\n",
      "  11. woz_value\n",
      "  12. pct_unoccupied\n",
      "  13. pct_owner_occupied\n",
      "  14. pct_rental\n",
      "  15. n_high_education\n",
      "  16. income_recipient\n",
      "  17. income_inhabitant\n",
      "  18. income_household\n",
      "  19. pct_bottom40\n",
      "  20. pct_top20\n",
      "  21. pct_low_income\n",
      "  22. pct_below_120pct_social_min\n",
      "  23. urbanicity\n",
      "  24. buurtcode_2022\n",
      "  25. buurt_cbs_2015\n",
      "  26. buurt_cbs_2022\n",
      "  27. year\n",
      "  28. facility_id\n",
      "  29. districts_and_neighbourhoods\n",
      "  30. municipality_name_fac\n",
      "  31. supermarkets_1km\n",
      "  32. food_shops_1km\n",
      "  33. cafes_1km\n",
      "  34. cafeterias_1km\n",
      "  35. restaurants_1km\n",
      "  36. dist_primary_school\n",
      "  37. dist_secondary_school\n",
      "  38. dist_train_station\n",
      "  39. buurt_name\n",
      "  40. wijk_name\n",
      "  41. stadsdeel_name\n",
      "  42. buurt_area_m2\n",
      "  43. dist_nearest_green_2020\n",
      "  44. nearest_green_name_2020\n",
      "  45. nearest_green_type_2020\n",
      "  46. nearest_green_area_m2_2020\n",
      "  47. total_green_area_m2_2020\n",
      "  48. green_coverage_pct_2020\n",
      "  49. num_green_spaces_2020\n",
      "  50. dist_nearest_green_2024\n",
      "  51. nearest_green_name_2024\n",
      "  52. nearest_green_type_2024\n",
      "  53. nearest_green_area_m2_2024\n",
      "  54. total_green_area_m2_2024\n",
      "  55. green_coverage_pct_2024\n",
      "  56. num_green_spaces_2024\n",
      "\n",
      "Green metrics 2020 columns (7):\n",
      "  - dist_nearest_green_2020\n",
      "  - nearest_green_name_2020\n",
      "  - nearest_green_type_2020\n",
      "  - nearest_green_area_m2_2020\n",
      "  - total_green_area_m2_2020\n",
      "  - green_coverage_pct_2020\n",
      "  - num_green_spaces_2020\n",
      "\n",
      "Green metrics 2024 columns (7):\n",
      "  - dist_nearest_green_2024\n",
      "  - nearest_green_name_2024\n",
      "  - nearest_green_type_2024\n",
      "  - nearest_green_area_m2_2024\n",
      "  - total_green_area_m2_2024\n",
      "  - green_coverage_pct_2024\n",
      "  - num_green_spaces_2024\n",
      "\n",
      "================================================================================\n",
      "STEP 9: Data quality check\n",
      "================================================================================\n",
      "\n",
      "Missing values per column:\n",
      "                             Missing  Percent\n",
      "nearest_green_name_2024          439     50.0\n",
      "total_green_area_m2_2024         439     50.0\n",
      "nearest_green_area_m2_2024       439     50.0\n",
      "num_green_spaces_2020            439     50.0\n",
      "dist_nearest_green_2024          439     50.0\n",
      "green_coverage_pct_2020          439     50.0\n",
      "total_green_area_m2_2020         439     50.0\n",
      "nearest_green_type_2020          439     50.0\n",
      "nearest_green_area_m2_2020       439     50.0\n",
      "dist_nearest_green_2020          439     50.0\n",
      "nearest_green_name_2020          439     50.0\n",
      "green_coverage_pct_2024          439     50.0\n",
      "num_green_spaces_2024            439     50.0\n",
      "nearest_green_type_2024          439     50.0\n",
      "n_high_education                 207     23.6\n",
      "woz_value                        121     13.8\n",
      "pct_unoccupied                   108     12.3\n",
      "pct_owner_occupied               108     12.3\n",
      "pct_rental                       108     12.3\n",
      "income_household                  70      8.0\n",
      "income_recipient                  52      5.9\n",
      "income_inhabitant                 46      5.2\n",
      "avg_household_size                16      1.8\n",
      "pct_top20                         12      1.4\n",
      "pct_bottom40                      12      1.4\n",
      "pct_below_120pct_social_min       12      1.4\n",
      "pct_low_income                    12      1.4\n",
      "\n",
      "Sample (first 2 rows each year):\n",
      "buurtcode_2022  year          buurt_name             wijk_name  income_inhabitant  green_coverage_pct_2020  green_coverage_pct_2024 woz_value restaurants_1km dist_train_station\n",
      "          AE01  2020         Kop Zeedijk Burgwallen-Oude Zijde               37.0                      0.0                      NaN     423.0           295.7                0.4\n",
      "          AE02  2020      Oude Kerk e.o. Burgwallen-Oude Zijde               31.5                      0.0                      NaN     440.0           330.2                0.7\n",
      "          AA01  2024 Planciusbuurt-Noord       Haarlemmerbuurt               45.4                      NaN                      0.0     392.0            53.7                2.2\n",
      "          AA02  2024 Westelijke eilanden       Haarlemmerbuurt               41.7                      NaN                      1.3     598.0            28.7                2.1\n",
      "\n",
      "================================================================================\n",
      "STEP 10: Save\n",
      "================================================================================\n",
      "✓ Saved: merged_buurt_panel_data.csv\n",
      "  Shape: (878, 56)\n",
      "  Columns: 56\n",
      "  Rows per year: 2020=439, 2024=439\n",
      "\n",
      "================================================================================\n",
      "VERIFICATION: Check both years' green metrics are present\n",
      "================================================================================\n",
      "2020 rows have 2020 green data: 439/439\n",
      "2020 rows have 2024 green data: 0/439\n",
      "2024 rows have 2020 green data: 0/439\n",
      "2024 rows have 2024 green data: 439/439\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STEP 1: Loading all files\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load with correct separators and decimal handling\n",
    "kern_2020 = pd.read_csv('../data/filtered_Kerncijfers_wijken_en_buurten_2020.csv', \n",
    "                         sep=';', decimal=',')\n",
    "kern_2024 = pd.read_csv('../data/filtered_Kerncijfers_wijken_en_buurten_2024.csv', \n",
    "                         sep=';', decimal=',')\n",
    "green_metrics = pd.read_csv('../data/filtered_buurt_green_metrics.csv')\n",
    "facilities_2020 = pd.read_csv('../data/filtered_proximity_to_facilities_2020.csv', sep=';', decimal=',')\n",
    "facilities_2024 = pd.read_csv('../data/filtered_proximity_to_facilities_2024.csv', sep=';', decimal=',')\n",
    "buurten_mapping = pd.read_csv('../data/buurten.csv')\n",
    "\n",
    "print(f\"Kern 2020: {len(kern_2020)} rows, {kern_2020.shape[1]} columns\")\n",
    "print(f\"Kern 2024: {len(kern_2024)} rows, {kern_2024.shape[1]} columns\")\n",
    "print(f\"Green: {len(green_metrics)} rows, {green_metrics.shape[1]} columns\")\n",
    "print(f\"Facilities 2020: {len(facilities_2020)} rows, {facilities_2020.shape[1]} columns\")\n",
    "print(f\"Facilities 2024: {len(facilities_2024)} rows, {facilities_2024.shape[1]} columns\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: Create mappings\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# CBS codes to BUURTCODE_2022\n",
    "cbs2015_to_buurt = dict(zip(buurten_mapping['BUURTCODE_CBS_2015'], \n",
    "                            buurten_mapping['BUURTCODE_2022']))\n",
    "cbs2022_to_buurt = dict(zip(buurten_mapping['BUURTCODE_CBS_2022'], \n",
    "                            buurten_mapping['BUURTCODE_2022']))\n",
    "\n",
    "# Reverse mappings\n",
    "buurt_to_cbs2015 = dict(zip(buurten_mapping['BUURTCODE_2022'],\n",
    "                            buurten_mapping['BUURTCODE_CBS_2015']))\n",
    "buurt_to_cbs2022 = dict(zip(buurten_mapping['BUURTCODE_2022'],\n",
    "                            buurten_mapping['BUURTCODE_CBS_2022']))\n",
    "\n",
    "print(f\"Mappings created\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: Define comprehensive column renaming\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# KERNCIJFERS COLUMNS (same for both 2020 and 2024)\n",
    "kerncijfers_rename = {\n",
    "    'District_Type': 'district_type',\n",
    "    'Municipality_Name': 'municipality_name',\n",
    "    'Area_Code': 'area_code_original',\n",
    "    'Population_Total': 'population_total',\n",
    "    'Pop_Age_0_15': 'pop_age_0_15',\n",
    "    'Pop_Age_15_25': 'pop_age_15_25',\n",
    "    'Pop_Age_25_45': 'pop_age_25_45',\n",
    "    'Pop_Age_45_65': 'pop_age_45_65',\n",
    "    'Pop_Age_65_Plus': 'pop_age_65_plus',\n",
    "    'Avg_Household_Size': 'avg_household_size',\n",
    "    'Avg_Property_Value_1000EUR': 'woz_value',\n",
    "    'Pct_Unoccupied_Homes': 'pct_unoccupied',\n",
    "    'Pct_Owner_Occupied': 'pct_owner_occupied',\n",
    "    'Pct_Rental': 'pct_rental',\n",
    "    'Higher_Education_Count': 'n_high_education',\n",
    "    'Avg_Income_Per_Income_Recipient_1000EUR': 'income_recipient',\n",
    "    'Avg_Income_Per_Inhabitant_1000EUR': 'income_inhabitant',\n",
    "    'Avg_Std_Household_Income_1000EUR': 'income_household',\n",
    "    'Pct_Lowest_40Pct_Income': 'pct_bottom40',\n",
    "    'Pct_Highest_20Pct_Income': 'pct_top20',\n",
    "    'Pct_Low_Income_Households': 'pct_low_income',\n",
    "    'Pct_Below_120Pct_Social_Min': 'pct_below_120pct_social_min',\n",
    "    'Urbanization_Level': 'urbanicity'\n",
    "}\n",
    "\n",
    "# FACILITIES 2020 COLUMNS\n",
    "facilities_2020_rename = {\n",
    "    'ID': 'facility_id',\n",
    "    'DistrictsAndNeighbourhoods': 'districts_and_neighbourhoods',\n",
    "    'MunicipalityName': 'municipality_name_fac',\n",
    "    'Encoding': 'encoding_original',\n",
    "    'supermarkets_within_1km': 'supermarkets_1km',\n",
    "    'food_shops_within_1km': 'food_shops_1km',\n",
    "    'cafes_within_1km': 'cafes_1km',\n",
    "    'cafeterias_within_1km': 'cafeterias_1km',\n",
    "    'restaurants_within_1km': 'restaurants_1km',\n",
    "    'distance_to_primary_school': 'dist_primary_school',\n",
    "    'distance_to_secondary_school': 'dist_secondary_school',\n",
    "    'DistanceToTrainStationAllTypes': 'dist_train_station'\n",
    "}\n",
    "\n",
    "# FACILITIES 2024 COLUMNS (note differences in column names)\n",
    "facilities_2024_rename = {\n",
    "    'ID': 'facility_id',\n",
    "    'DistrictsAndNeighbourhoods': 'districts_and_neighbourhoods',\n",
    "    'MunicipalityName_1': 'municipality_name_fac',\n",
    "    'Encoding_3': 'encoding_original',\n",
    "    'supermarkets_within_1km': 'supermarkets_1km',\n",
    "    'food_shops_within_1km': 'food_shops_1km',\n",
    "    'cafes_within_1km': 'cafes_1km',\n",
    "    'cafeterias_within_1km': 'cafeterias_1km',\n",
    "    'restaurants_within_1km': 'restaurants_1km',\n",
    "    'distance_to_primary_school': 'dist_primary_school',\n",
    "    'distance_to_secondary_school': 'dist_secondary_school',\n",
    "    'DistanceToTrainStationAllTypes_90': 'dist_train_station'\n",
    "}\n",
    "\n",
    "print(\"Column renaming dictionaries defined\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: Process GREEN METRICS (both years combined)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Extract metadata (same for both years)\n",
    "green_metadata = green_metrics[['BUURTCODE_2022', 'BUURTNAAM_2022', 'WIJKNAAM_2022', \n",
    "                                 'STADSDEELNAAM', 'buurt_area_m2']].copy()\n",
    "green_metadata = green_metadata.rename(columns={\n",
    "    'BUURTCODE_2022': 'buurtcode_2022',\n",
    "    'BUURTNAAM_2022': 'buurt_name',\n",
    "    'WIJKNAAM_2022': 'wijk_name',\n",
    "    'STADSDEELNAAM': 'stadsdeel_name',\n",
    "    'buurt_area_m2': 'buurt_area_m2'\n",
    "})\n",
    "\n",
    "# Extract 2020 metrics with year suffix\n",
    "green_2020 = green_metrics[['BUURTCODE_2022', \n",
    "                            'distance_to_nearest_green_m_2020',\n",
    "                            'nearest_green_name_2020',\n",
    "                            'nearest_green_type_2020',\n",
    "                            'nearest_green_area_m2_2020',\n",
    "                            'total_green_area_m2_2020',\n",
    "                            'green_coverage_percent_2020',\n",
    "                            'num_green_spaces_2020']].copy()\n",
    "\n",
    "green_2020 = green_2020.rename(columns={\n",
    "    'BUURTCODE_2022': 'buurtcode_2022',\n",
    "    'distance_to_nearest_green_m_2020': 'dist_nearest_green_2020',\n",
    "    'nearest_green_name_2020': 'nearest_green_name_2020',\n",
    "    'nearest_green_type_2020': 'nearest_green_type_2020',\n",
    "    'nearest_green_area_m2_2020': 'nearest_green_area_m2_2020',\n",
    "    'total_green_area_m2_2020': 'total_green_area_m2_2020',\n",
    "    'green_coverage_percent_2020': 'green_coverage_pct_2020',\n",
    "    'num_green_spaces_2020': 'num_green_spaces_2020'\n",
    "})\n",
    "\n",
    "# Extract 2024 metrics with year suffix\n",
    "green_2024 = green_metrics[['BUURTCODE_2022',\n",
    "                            'distance_to_nearest_green_m_2024',\n",
    "                            'nearest_green_name_2024',\n",
    "                            'nearest_green_type_2024',\n",
    "                            'nearest_green_area_m2_2024',\n",
    "                            'total_green_area_m2_2024',\n",
    "                            'green_coverage_percent_2024',\n",
    "                            'num_green_spaces_2024']].copy()\n",
    "\n",
    "green_2024 = green_2024.rename(columns={\n",
    "    'BUURTCODE_2022': 'buurtcode_2022',\n",
    "    'distance_to_nearest_green_m_2024': 'dist_nearest_green_2024',\n",
    "    'nearest_green_name_2024': 'nearest_green_name_2024',\n",
    "    'nearest_green_type_2024': 'nearest_green_type_2024',\n",
    "    'nearest_green_area_m2_2024': 'nearest_green_area_m2_2024',\n",
    "    'total_green_area_m2_2024': 'total_green_area_m2_2024',\n",
    "    'green_coverage_percent_2024': 'green_coverage_pct_2024',\n",
    "    'num_green_spaces_2024': 'num_green_spaces_2024'\n",
    "})\n",
    "\n",
    "# Merge metadata + 2020 + 2024 into single green dataframe\n",
    "green_combined = green_metadata.merge(green_2020, on='buurtcode_2022', how='outer')\n",
    "green_combined = green_combined.merge(green_2024, on='buurtcode_2022', how='outer')\n",
    "\n",
    "print(f\"Green combined: {len(green_combined)} rows, {len(green_combined.columns)} columns\")\n",
    "print(f\"Columns: {list(green_combined.columns)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 5: Process 2020 data (ALL COLUMNS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Kerncijfers 2020\n",
    "k20 = kern_2020.copy()\n",
    "k20 = k20.rename(columns=kerncijfers_rename)\n",
    "k20['buurtcode_2022'] = k20['area_code_original'].map(cbs2015_to_buurt)\n",
    "k20['buurt_cbs_2015'] = k20['area_code_original']\n",
    "k20['buurt_cbs_2022'] = k20['buurtcode_2022'].map(buurt_to_cbs2022)\n",
    "k20['year'] = 2020\n",
    "\n",
    "print(f\"K20 columns after rename: {len(k20.columns)}\")\n",
    "\n",
    "# Facilities 2020\n",
    "f20 = facilities_2020.copy()\n",
    "f20 = f20.rename(columns=facilities_2020_rename)\n",
    "f20['buurtcode_2022'] = f20['encoding_original'].map(cbs2015_to_buurt)\n",
    "\n",
    "print(f\"F20 columns after rename: {len(f20.columns)}\")\n",
    "\n",
    "# Select green columns for 2020 (metadata + 2020 metrics only)\n",
    "green_cols_2020 = ['buurtcode_2022', 'buurt_name', 'wijk_name', 'stadsdeel_name', \n",
    "                   'buurt_area_m2'] + [col for col in green_combined.columns if '2020' in col]\n",
    "g20 = green_combined[green_cols_2020].copy()\n",
    "\n",
    "print(f\"G20 columns selected: {len(g20.columns)}\")\n",
    "\n",
    "# Merge 2020 - keep ALL columns\n",
    "data_2020 = k20.merge(f20.drop(columns=['encoding_original']), \n",
    "                       on='buurtcode_2022', how='left', suffixes=('', '_fac'))\n",
    "data_2020 = data_2020.merge(g20, on='buurtcode_2022', how='left')\n",
    "\n",
    "print(f\"2020 data: {len(data_2020)} rows, {len(data_2020.columns)} columns\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 6: Process 2024 data (ALL COLUMNS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Kerncijfers 2024\n",
    "k24 = kern_2024.copy()\n",
    "k24 = k24.rename(columns=kerncijfers_rename)\n",
    "k24['buurtcode_2022'] = k24['area_code_original'].map(cbs2022_to_buurt)\n",
    "k24['buurt_cbs_2022'] = k24['area_code_original']\n",
    "k24['buurt_cbs_2015'] = k24['buurtcode_2022'].map(buurt_to_cbs2015)\n",
    "k24['year'] = 2024\n",
    "\n",
    "print(f\"K24 columns after rename: {len(k24.columns)}\")\n",
    "\n",
    "# Facilities 2024\n",
    "f24 = facilities_2024.copy()\n",
    "f24 = f24.rename(columns=facilities_2024_rename)\n",
    "f24['buurtcode_2022'] = f24['encoding_original'].map(cbs2022_to_buurt)\n",
    "\n",
    "print(f\"F24 columns after rename: {len(f24.columns)}\")\n",
    "\n",
    "# Select green columns for 2024 (metadata + 2024 metrics only)\n",
    "green_cols_2024 = ['buurtcode_2022', 'buurt_name', 'wijk_name', 'stadsdeel_name', \n",
    "                   'buurt_area_m2'] + [col for col in green_combined.columns if '2024' in col]\n",
    "g24 = green_combined[green_cols_2024].copy()\n",
    "\n",
    "print(f\"G24 columns selected: {len(g24.columns)}\")\n",
    "\n",
    "# Merge 2024 - keep ALL columns\n",
    "data_2024 = k24.merge(f24.drop(columns=['encoding_original']), \n",
    "                       on='buurtcode_2022', how='left', suffixes=('', '_fac'))\n",
    "data_2024 = data_2024.merge(g24, on='buurtcode_2022', how='left')\n",
    "\n",
    "print(f\"2024 data: {len(data_2024)} rows, {len(data_2024.columns)} columns\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 7: Combine to long format\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Stack\n",
    "final_data = pd.concat([data_2020, data_2024], ignore_index=True)\n",
    "\n",
    "# Remove missing buurtcodes\n",
    "final_data = final_data.dropna(subset=['buurtcode_2022'])\n",
    "\n",
    "print(f\"Final: {len(final_data)} rows\")\n",
    "print(f\"Unique buurten: {final_data['buurtcode_2022'].nunique()}\")\n",
    "print(f\"Total columns: {len(final_data.columns)}\")\n",
    "print(f\"Rows by year:\\n{final_data['year'].value_counts().sort_index()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 8: Column inventory\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nAll columns in final dataset:\")\n",
    "for i, col in enumerate(final_data.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# Identify green columns\n",
    "green_2020_cols_in_final = [col for col in final_data.columns if '2020' in col]\n",
    "green_2024_cols_in_final = [col for col in final_data.columns if '2024' in col]\n",
    "\n",
    "print(f\"\\nGreen metrics 2020 columns ({len(green_2020_cols_in_final)}):\")\n",
    "for col in green_2020_cols_in_final:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(f\"\\nGreen metrics 2024 columns ({len(green_2024_cols_in_final)}):\")\n",
    "for col in green_2024_cols_in_final:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 9: Data quality check\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "missing = final_data.isnull().sum()\n",
    "missing_pct = (missing / len(final_data) * 100).round(1)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing': missing[missing > 0],\n",
    "    'Percent': missing_pct[missing > 0]\n",
    "}).sort_values('Missing', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df.to_string())\n",
    "else:\n",
    "    print(\"No missing values!\")\n",
    "\n",
    "print(\"\\nSample (first 2 rows each year):\")\n",
    "sample_cols = ['buurtcode_2022', 'year', 'buurt_name', 'wijk_name', \n",
    "               'income_inhabitant', 'green_coverage_pct_2020', 'green_coverage_pct_2024',\n",
    "               'woz_value', 'restaurants_1km', 'dist_train_station']\n",
    "available_cols = [col for col in sample_cols if col in final_data.columns]\n",
    "print(final_data.groupby('year').head(2)[available_cols].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 10: Save\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "final_data.to_csv('../data/merged_buurt_panel_data.csv', index=False)\n",
    "print(f\"✓ Saved: merged_buurt_panel_data.csv\")\n",
    "print(f\"  Shape: {final_data.shape}\")\n",
    "print(f\"  Columns: {len(final_data.columns)}\")\n",
    "print(f\"  Rows per year: 2020={len(final_data[final_data['year']==2020])}, 2024={len(final_data[final_data['year']==2024])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERIFICATION: Check both years' green metrics are present\")\n",
    "print(\"=\"*80)\n",
    "print(f\"2020 rows have 2020 green data: {final_data[final_data['year']==2020]['green_coverage_pct_2020'].notna().sum()}/{len(final_data[final_data['year']==2020])}\")\n",
    "print(f\"2020 rows have 2024 green data: {final_data[final_data['year']==2020]['green_coverage_pct_2024'].notna().sum()}/{len(final_data[final_data['year']==2020])}\")\n",
    "print(f\"2024 rows have 2020 green data: {final_data[final_data['year']==2024]['green_coverage_pct_2020'].notna().sum()}/{len(final_data[final_data['year']==2024])}\")\n",
    "print(f\"2024 rows have 2024 green data: {final_data[final_data['year']==2024]['green_coverage_pct_2024'].notna().sum()}/{len(final_data[final_data['year']==2024])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e63f93",
   "metadata": {},
   "source": [
    "### remove leading whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ca313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Removed leading/trailing whitespaces\n",
      "Shape: (878, 56)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/merged_buurt_panel_data.csv')\n",
    "\n",
    "# Strip whitespace from all string columns\n",
    "df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv('../data/merged_buurt_panel_data.csv', index=False)\n",
    "\n",
    "print(\"✓ Removed leading/trailing whitespaces\")\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14867843",
   "metadata": {},
   "source": [
    "### now save a copy of the merged_buurt_panel_data.csv file to be able to run tests on the non-imputed dataset later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5b3ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved copy as non_imputed_merged_buurt_panel_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the current merged_buurt_panel_data.csv\n",
    "df = pd.read_csv('../data/merged_buurt_panel_data.csv')\n",
    "\n",
    "# Save a copy with the new name\n",
    "df.to_csv('../data/non_imputed_merged_buurt_panel_data.csv', index=False)\n",
    "\n",
    "print(\"✓ Saved copy as non_imputed_merged_buurt_panel_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ebee44",
   "metadata": {},
   "source": [
    "## 🧮 account for missing values: KNN imputation strategy\n",
    "\n",
    "We handle missing values using **context-aware KNN imputation**, applied in **three separate batches** to reduce bias and avoid circular leakage between related socioeconomic variables.\n",
    "\n",
    "### 🔹 Overview\n",
    "Instead of imputing all variables at once, we impute them in **groups** with contextually relevant features:\n",
    "- Each batch has its own **target variables** (to be imputed)\n",
    "- and **context features** (used to find similar neighborhoods)\n",
    "\n",
    "This approach ensures that:\n",
    "- Income variables aren’t imputed using other income measures directly  \n",
    "- Housing variables are informed by spatial and demographic context  \n",
    "- Education and household size are imputed using population and income characteristics  \n",
    "\n",
    "### 🔹 Batches\n",
    "1. **Housing characteristics** → `woz_value`, `pct_unoccupied`, `pct_owner_occupied`, `pct_rental`  \n",
    "   *Context:* urbanicity, population, facilities, green area, etc.  \n",
    "\n",
    "2. **Income-related** → `income_household`, `income_recipient`, `income_inhabitant`, `pct_top20`, `pct_bottom40`, `pct_low_income`, `pct_below_120pct_social_min`  \n",
    "   *Context:* urbanicity, education, housing, and population structure  \n",
    "\n",
    "3. **Education & household composition** → `n_high_education`, `avg_household_size`  \n",
    "   *Context:* income, age structure, urbanicity  \n",
    "\n",
    "### 🔹 Implementation Notes\n",
    "- Uses `KNNImputer(n_neighbors=5, weights='distance')`  \n",
    "- All variables converted to numeric (`errors='coerce'`)  \n",
    "- Each batch validated with summary statistics (mean, median, min, max)  \n",
    "- Original data saved as `non_imputed_merged_buurt_panel_data.csv` for comparison  \n",
    "- Final imputed dataset exported as `merged_buurt_panel_data_imputed.csv`  \n",
    "\n",
    "This modular setup preserves interpretability and statistical validity for subsequent analysis (e.g., DiD regression).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f35615",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Why KNN imputation instead of median?\n",
    "\n",
    "KNN uses similar buurten to fill values (e.g., if Buurt A is missing pct_low_income, it looks at the 5 most similar buurten based on urbanicity, population, green coverage, etc.)\n",
    "More accurate than simple median\n",
    "Preserves relationships between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f078d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CONTEXT-AWARE BATCH KNN IMPUTATION\n",
      "================================================================================\n",
      "\n",
      "Total rows: 878\n",
      "Total columns: 56\n",
      "\n",
      "Rows by year:\n",
      "year\n",
      "2020    439\n",
      "2024    439\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "Missing values before imputation (all relevant variables):\n",
      "================================================================================\n",
      "n_high_education               207\n",
      "woz_value                      121\n",
      "pct_unoccupied                 108\n",
      "pct_rental                     108\n",
      "pct_owner_occupied             108\n",
      "income_household                70\n",
      "income_recipient                52\n",
      "income_inhabitant               46\n",
      "avg_household_size              16\n",
      "pct_bottom40                    12\n",
      "pct_top20                       12\n",
      "pct_low_income                  12\n",
      "pct_below_120pct_social_min     12\n",
      "dtype: int64\n",
      "\n",
      "================================================================================\n",
      "BATCH 1: Housing Characteristics\n",
      "================================================================================\n",
      "\n",
      "Targets: ['woz_value', 'pct_unoccupied', 'pct_owner_occupied', 'pct_rental']\n",
      "Context features: 8 features\n",
      "  Imputation matrix shape (rows,cols): (878, 12)\n",
      "  Columns used: ['woz_value', 'pct_unoccupied', 'pct_owner_occupied', 'pct_rental', 'urbanicity', 'population_total', 'avg_household_size', 'dist_train_station', 'dist_primary_school', 'supermarkets_1km', 'restaurants_1km', 'year']\n",
      "  Missing values in batch before imputation:\n",
      "    woz_value: 121\n",
      "    pct_unoccupied: 108\n",
      "    pct_owner_occupied: 108\n",
      "    pct_rental: 108\n",
      "  Imputed array shape: (878, 12)\n",
      "\n",
      "  Validation - Imputed housing variables:\n",
      "\n",
      "  woz_value:\n",
      "    Mean: 532.14\n",
      "    Median: 475.00\n",
      "    Min: 31.00\n",
      "    Max: 2206.00\n",
      "    Still missing: 0\n",
      "\n",
      "  pct_unoccupied:\n",
      "    Mean: 9.74\n",
      "    Median: 6.00\n",
      "    Min: 0.00\n",
      "    Max: 60.00\n",
      "    Still missing: 0\n",
      "\n",
      "  pct_owner_occupied:\n",
      "    Mean: 34.17\n",
      "    Median: 32.00\n",
      "    Min: 0.00\n",
      "    Max: 100.00\n",
      "    Still missing: 0\n",
      "\n",
      "  pct_rental:\n",
      "    Mean: 65.63\n",
      "    Median: 68.00\n",
      "    Min: 0.00\n",
      "    Max: 100.00\n",
      "    Still missing: 0\n",
      "\n",
      "================================================================================\n",
      "BATCH 2: Income-Related Variables\n",
      "================================================================================\n",
      "\n",
      "Targets: ['income_household', 'income_recipient', 'income_inhabitant', 'pct_top20', 'pct_bottom40', 'pct_below_120pct_social_min', 'pct_low_income']\n",
      "Context features: 8 features\n",
      "  Imputation matrix shape (rows,cols): (878, 15)\n",
      "  Columns used: ['income_household', 'income_recipient', 'income_inhabitant', 'pct_top20', 'pct_bottom40', 'pct_below_120pct_social_min', 'pct_low_income', 'urbanicity', 'woz_value', 'n_high_education', 'avg_household_size', 'pct_owner_occupied', 'pct_rental', 'population_total', 'year']\n",
      "  Missing values in batch before imputation:\n",
      "    income_household: 70\n",
      "    income_recipient: 52\n",
      "    income_inhabitant: 46\n",
      "    pct_top20: 12\n",
      "    pct_bottom40: 12\n",
      "    pct_below_120pct_social_min: 12\n",
      "    pct_low_income: 12\n",
      "  Imputed array shape: (878, 15)\n",
      "\n",
      "  Validation - Imputed income variables:\n",
      "\n",
      "  income_household:\n",
      "    Mean: 38.58\n",
      "    Median: 35.15\n",
      "    Min: 10.30\n",
      "    Max: 124.10\n",
      "    Still missing: 0\n",
      "\n",
      "  income_recipient:\n",
      "    Mean: 45.61\n",
      "    Median: 42.60\n",
      "    Min: 12.40\n",
      "    Max: 177.00\n",
      "    Still missing: 0\n",
      "\n",
      "  income_inhabitant:\n",
      "    Mean: 37.79\n",
      "    Median: 35.95\n",
      "    Min: 11.00\n",
      "    Max: 134.40\n",
      "    Still missing: 0\n",
      "\n",
      "  pct_top20:\n",
      "    Mean: 19.29\n",
      "    Median: 16.45\n",
      "    Min: 0.00\n",
      "    Max: 60.00\n",
      "    Still missing: 0\n",
      "\n",
      "  pct_bottom40:\n",
      "    Mean: 49.39\n",
      "    Median: 50.20\n",
      "    Min: 12.90\n",
      "    Max: 98.40\n",
      "    Still missing: 0\n",
      "\n",
      "  pct_below_120pct_social_min:\n",
      "    Mean: 17.53\n",
      "    Median: 16.70\n",
      "    Min: 1.30\n",
      "    Max: 56.20\n",
      "    Still missing: 0\n",
      "\n",
      "  pct_low_income:\n",
      "    Mean: 10.36\n",
      "    Median: 9.50\n",
      "    Min: 1.30\n",
      "    Max: 47.50\n",
      "    Still missing: 0\n",
      "\n",
      "================================================================================\n",
      "BATCH 3: Education and Household Composition\n",
      "================================================================================\n",
      "\n",
      "Targets: ['n_high_education', 'avg_household_size']\n",
      "Context features: 8 features\n",
      "  Imputation matrix shape (rows,cols): (878, 10)\n",
      "  Columns used: ['n_high_education', 'avg_household_size', 'urbanicity', 'income_household', 'woz_value', 'population_total', 'pop_age_25_45', 'pop_age_45_65', 'pop_age_65_plus', 'year']\n",
      "  Missing values in batch before imputation:\n",
      "    n_high_education: 207\n",
      "    avg_household_size: 16\n",
      "  Imputed array shape: (878, 10)\n",
      "\n",
      "  Validation - Imputed education/household variables:\n",
      "\n",
      "  n_high_education:\n",
      "    Mean: 760.69\n",
      "    Median: 630.00\n",
      "    Min: 10.00\n",
      "    Max: 3570.00\n",
      "    Still missing: 0\n",
      "\n",
      "  avg_household_size:\n",
      "    Mean: 1.80\n",
      "    Median: 1.70\n",
      "    Min: 1.00\n",
      "    Max: 3.60\n",
      "    Still missing: 0\n",
      "\n",
      "================================================================================\n",
      "BATCH 4: Facility Variables\n",
      "================================================================================\n",
      "\n",
      "Targets: ['restaurants_1km', 'cafes_1km', 'cafeterias_1km', 'dist_primary_school', 'dist_train_station', 'supermarkets_1km', 'food_shops_1km', 'dist_secondary_school']\n",
      "Context features: 6 features\n",
      "  Imputation matrix shape (rows,cols): (878, 14)\n",
      "  Columns used: ['restaurants_1km', 'cafes_1km', 'cafeterias_1km', 'dist_primary_school', 'dist_train_station', 'supermarkets_1km', 'food_shops_1km', 'dist_secondary_school', 'urbanicity', 'population_total', 'avg_household_size', 'woz_value', 'income_household', 'year']\n",
      "  Missing values in batch before imputation:\n",
      "    restaurants_1km: 44\n",
      "    cafes_1km: 44\n",
      "    cafeterias_1km: 44\n",
      "    dist_primary_school: 44\n",
      "    dist_train_station: 44\n",
      "    supermarkets_1km: 44\n",
      "    food_shops_1km: 44\n",
      "    dist_secondary_school: 44\n",
      "  Imputed array shape: (878, 14)\n",
      "\n",
      "  Validation - Imputed facility variables:\n",
      "\n",
      "  restaurants_1km:\n",
      "    Mean: 47.81\n",
      "    Median: 17.30\n",
      "    Min: 0.00\n",
      "    Max: 375.30\n",
      "    Still missing: 0\n",
      "\n",
      "  cafes_1km:\n",
      "    Mean: 17.28\n",
      "    Median: 2.90\n",
      "    Min: 0.00\n",
      "    Max: 228.40\n",
      "    Still missing: 0\n",
      "\n",
      "  cafeterias_1km:\n",
      "    Mean: 23.26\n",
      "    Median: 9.75\n",
      "    Min: 0.00\n",
      "    Max: 261.10\n",
      "    Still missing: 0\n",
      "\n",
      "  dist_primary_school:\n",
      "    Mean: 0.76\n",
      "    Median: 0.60\n",
      "    Min: 0.10\n",
      "    Max: 5.30\n",
      "    Still missing: 0\n",
      "\n",
      "  dist_train_station:\n",
      "    Mean: 2.69\n",
      "    Median: 2.30\n",
      "    Min: 0.10\n",
      "    Max: 10.20\n",
      "    Still missing: 0\n",
      "\n",
      "  supermarkets_1km:\n",
      "    Mean: 4.13\n",
      "    Median: 3.10\n",
      "    Min: 0.00\n",
      "    Max: 17.10\n",
      "    Still missing: 0\n",
      "\n",
      "  food_shops_1km:\n",
      "    Mean: 25.38\n",
      "    Median: 12.80\n",
      "    Min: 0.00\n",
      "    Max: 178.00\n",
      "    Still missing: 0\n",
      "\n",
      "  dist_secondary_school:\n",
      "    Mean: 1.15\n",
      "    Median: 1.00\n",
      "    Min: 0.10\n",
      "    Max: 7.20\n",
      "    Still missing: 0\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY: Missing values after all batches\n",
      "================================================================================\n",
      "dist_nearest_green_2020       439\n",
      "nearest_green_name_2020       439\n",
      "nearest_green_type_2020       439\n",
      "nearest_green_area_m2_2020    439\n",
      "total_green_area_m2_2020      439\n",
      "green_coverage_pct_2020       439\n",
      "num_green_spaces_2020         439\n",
      "dist_nearest_green_2024       439\n",
      "nearest_green_name_2024       439\n",
      "nearest_green_type_2024       439\n",
      "nearest_green_area_m2_2024    439\n",
      "total_green_area_m2_2024      439\n",
      "green_coverage_pct_2024       439\n",
      "num_green_spaces_2024         439\n",
      "dtype: int64\n",
      "\n",
      "================================================================================\n",
      "Comparing with non-imputed dataset\n",
      "================================================================================\n",
      "\n",
      "Imputation effectiveness:\n",
      "  woz_value:\n",
      "    Before: 121 missing (13.8%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 121 values imputed (100.0% of missing)\n",
      "  pct_unoccupied:\n",
      "    Before: 108 missing (12.3%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 108 values imputed (100.0% of missing)\n",
      "  pct_owner_occupied:\n",
      "    Before: 108 missing (12.3%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 108 values imputed (100.0% of missing)\n",
      "  pct_rental:\n",
      "    Before: 108 missing (12.3%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 108 values imputed (100.0% of missing)\n",
      "  income_household:\n",
      "    Before: 70 missing (8.0%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 70 values imputed (100.0% of missing)\n",
      "  income_recipient:\n",
      "    Before: 52 missing (5.9%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 52 values imputed (100.0% of missing)\n",
      "  income_inhabitant:\n",
      "    Before: 46 missing (5.2%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 46 values imputed (100.0% of missing)\n",
      "  pct_top20:\n",
      "    Before: 12 missing (1.4%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 12 values imputed (100.0% of missing)\n",
      "  pct_bottom40:\n",
      "    Before: 12 missing (1.4%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 12 values imputed (100.0% of missing)\n",
      "  pct_below_120pct_social_min:\n",
      "    Before: 12 missing (1.4%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 12 values imputed (100.0% of missing)\n",
      "  pct_low_income:\n",
      "    Before: 12 missing (1.4%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 12 values imputed (100.0% of missing)\n",
      "  n_high_education:\n",
      "    Before: 207 missing (23.6%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 207 values imputed (100.0% of missing)\n",
      "  avg_household_size:\n",
      "    Before: 16 missing (1.8%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 16 values imputed (100.0% of missing)\n",
      "  restaurants_1km:\n",
      "    Before: 44 missing (5.0%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 44 values imputed (100.0% of missing)\n",
      "  cafes_1km:\n",
      "    Before: 44 missing (5.0%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 44 values imputed (100.0% of missing)\n",
      "  cafeterias_1km:\n",
      "    Before: 44 missing (5.0%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 44 values imputed (100.0% of missing)\n",
      "  dist_primary_school:\n",
      "    Before: 44 missing (5.0%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 44 values imputed (100.0% of missing)\n",
      "  dist_train_station:\n",
      "    Before: 44 missing (5.0%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 44 values imputed (100.0% of missing)\n",
      "  supermarkets_1km:\n",
      "    Before: 44 missing (5.0%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 44 values imputed (100.0% of missing)\n",
      "  food_shops_1km:\n",
      "    Before: 44 missing (5.0%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 44 values imputed (100.0% of missing)\n",
      "  dist_secondary_school:\n",
      "    Before: 44 missing (5.0%)\n",
      "    After: 0 missing (0.0%)\n",
      "    Improvement: 44 values imputed (100.0% of missing)\n",
      "\n",
      "================================================================================\n",
      "Saving imputed dataset\n",
      "================================================================================\n",
      "✓ Saved: merged_buurt_panel_data_imputed.csv\n",
      "\n",
      "Final dataset:\n",
      "  Rows: 878\n",
      "  Columns: 56\n",
      "  Complete cases (no missing): 0\n",
      "  Rows by year:\n",
      "year\n",
      "2020    439\n",
      "2024    439\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "Ready for DiD analysis!\n",
      "================================================================================\n",
      "\n",
      "Variables status:\n",
      "  Complete (no missing): ['woz_value', 'pct_unoccupied', 'pct_owner_occupied', 'pct_rental', 'income_household', 'income_recipient', 'income_inhabitant', 'pct_top20', 'pct_bottom40', 'pct_below_120pct_social_min', 'pct_low_income', 'n_high_education', 'avg_household_size', 'restaurants_1km', 'cafes_1km', 'cafeterias_1km', 'dist_primary_school', 'dist_train_station', 'supermarkets_1km', 'food_shops_1km', 'dist_secondary_school']\n",
      "  Incomplete (still missing): []\n",
      "\n",
      "Key variables for analysis:\n",
      "  Treatment: green_coverage_pct_2020, green_coverage_pct_2024\n",
      "  Outcomes: income_household, income_inhabitant, pct_low_income, woz_value\n",
      "  Controls: urbanicity, population_total, facilities, housing characteristics\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def knn_impute(df, target_vars, context_vars, k=5):\n",
    "    \"\"\"\n",
    "    KNN imputation with robust handling of column order, duplicate names and shape checks.\n",
    "    Replaces only the target_vars in the original df.\n",
    "    \"\"\"\n",
    "    # available columns\n",
    "    available_targets = [c for c in target_vars if c in df.columns]\n",
    "    available_context = [c for c in context_vars if c in df.columns]\n",
    "\n",
    "    if not available_targets:\n",
    "        print(\"  ⚠️  WARNING: No target variables found in dataframe!\")\n",
    "        return df\n",
    "\n",
    "    missing_targets = set(target_vars) - set(available_targets)\n",
    "    missing_context = set(context_vars) - set(available_context)\n",
    "    if missing_targets:\n",
    "        print(f\"  ⚠️  WARNING: Target variables not found: {missing_targets}\")\n",
    "    if missing_context:\n",
    "        print(f\"  ⚠️  WARNING: Context variables not found: {missing_context}\")\n",
    "\n",
    "    # preserve order and remove duplicates\n",
    "    all_vars = []\n",
    "    for c in available_targets + available_context:\n",
    "        if c not in all_vars:\n",
    "            all_vars.append(c)\n",
    "\n",
    "    # select columns (preserve dataframe column order if possible)\n",
    "    impute_df = df.loc[:, [c for c in all_vars if c in df.columns]].copy()\n",
    "\n",
    "    # drop duplicated column names if any (rare, but possible)\n",
    "    if impute_df.columns.duplicated().any():\n",
    "        dup = impute_df.columns[impute_df.columns.duplicated()].tolist()\n",
    "        print(f\"  ⚠️  Dropping duplicate column names: {dup}\")\n",
    "        impute_df = impute_df.loc[:, ~impute_df.columns.duplicated()]\n",
    "\n",
    "    # convert to numeric (coerce strings to NaN)\n",
    "    for col in impute_df.columns:\n",
    "        impute_df[col] = pd.to_numeric(impute_df[col], errors='coerce')\n",
    "\n",
    "    # debug info\n",
    "    print(f\"  Imputation matrix shape (rows,cols): {impute_df.shape}\")\n",
    "    print(f\"  Columns used: {list(impute_df.columns)}\")\n",
    "    \n",
    "    # Show missing values before imputation\n",
    "    print(f\"  Missing values in batch before imputation:\")\n",
    "    missing_counts = impute_df.isnull().sum()\n",
    "    for target in available_targets:\n",
    "        if target in missing_counts.index:\n",
    "            print(f\"    {target}: {missing_counts[target]}\")\n",
    "\n",
    "    # run imputer on numpy array\n",
    "    imputer = KNNImputer(n_neighbors=k, weights='distance')\n",
    "    arr = impute_df.to_numpy(dtype=float)\n",
    "    imputed_arr = imputer.fit_transform(arr)\n",
    "\n",
    "    print(f\"  Imputed array shape: {imputed_arr.shape}\")\n",
    "\n",
    "    # ensure column alignment; handle rare mismatch robustly\n",
    "    if imputed_arr.shape[1] != impute_df.shape[1]:\n",
    "        print(\"  ⚠️  Shape mismatch between imputed array and impute_df.columns.\")\n",
    "        cols = list(impute_df.columns)\n",
    "        if imputed_arr.shape[1] < len(cols):\n",
    "            cols = cols[:imputed_arr.shape[1]]\n",
    "            print(f\"  ⚠️  Trimming column list to: {cols}\")\n",
    "        else:\n",
    "            extras = [f\"imputed_extra_{i}\" for i in range(imputed_arr.shape[1] - len(cols))]\n",
    "            cols = cols + extras\n",
    "            print(f\"  ⚠️  Extending column list with: {extras}\")\n",
    "        imputed_df = pd.DataFrame(imputed_arr, columns=cols, index=df.index)\n",
    "    else:\n",
    "        imputed_df = pd.DataFrame(imputed_arr, columns=impute_df.columns, index=df.index)\n",
    "\n",
    "    # replace only the target variables (if present in imputed_df)\n",
    "    for var in available_targets:\n",
    "        if var in imputed_df.columns:\n",
    "            df[var] = imputed_df[var]\n",
    "        else:\n",
    "            print(f\"  ⚠️  Imputed result does not contain column '{var}' — skipping update.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CONTEXT-AWARE BATCH KNN IMPUTATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df = pd.read_csv('../data/merged_buurt_panel_data.csv', na_values=['.', '..', ''])\n",
    "\n",
    "print(f\"\\nTotal rows: {len(df)}\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "print(f\"\\nRows by year:\\n{df['year'].value_counts().sort_index()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Missing values before imputation (all relevant variables):\")\n",
    "print(\"=\"*80)\n",
    "relevant_vars = [\n",
    "    'woz_value', 'pct_unoccupied', 'pct_owner_occupied', 'pct_rental',\n",
    "    'income_household', 'income_recipient', 'income_inhabitant',\n",
    "    'pct_top20', 'pct_bottom40', 'pct_below_120pct_social_min', 'pct_low_income',\n",
    "    'n_high_education', 'avg_household_size'\n",
    "]\n",
    "missing_before = df[relevant_vars].isnull().sum()\n",
    "print(missing_before[missing_before > 0].sort_values(ascending=False))\n",
    "\n",
    "# ============================================================\n",
    "# BATCH 1: Housing characteristics\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BATCH 1: Housing Characteristics\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch1_targets = ['woz_value', 'pct_unoccupied', 'pct_owner_occupied', 'pct_rental']\n",
    "batch1_context = [\n",
    "    'urbanicity',\n",
    "    'population_total', 'avg_household_size',\n",
    "    'dist_train_station', 'dist_primary_school',\n",
    "    'supermarkets_1km', 'restaurants_1km',\n",
    "    'year'\n",
    "]\n",
    "\n",
    "print(f\"\\nTargets: {batch1_targets}\")\n",
    "print(f\"Context features: {len(batch1_context)} features\")\n",
    "\n",
    "df = knn_impute(df, batch1_targets, batch1_context, k=5)\n",
    "\n",
    "print(f\"\\n  Validation - Imputed housing variables:\")\n",
    "for var in batch1_targets:\n",
    "    if var in df.columns:\n",
    "        print(f\"\\n  {var}:\")\n",
    "        print(f\"    Mean: {df[var].mean():.2f}\")\n",
    "        print(f\"    Median: {df[var].median():.2f}\")\n",
    "        print(f\"    Min: {df[var].min():.2f}\")\n",
    "        print(f\"    Max: {df[var].max():.2f}\")\n",
    "        print(f\"    Still missing: {df[var].isnull().sum()}\")\n",
    "\n",
    "# ============================================================\n",
    "# BATCH 2: Income-related variables\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BATCH 2: Income-Related Variables\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch2_targets = [\n",
    "    'income_household', 'income_recipient', 'income_inhabitant',\n",
    "    'pct_top20', 'pct_bottom40', 'pct_below_120pct_social_min', 'pct_low_income'\n",
    "]\n",
    "batch2_context = [\n",
    "    'urbanicity',\n",
    "    'woz_value', 'n_high_education', 'avg_household_size',\n",
    "    'pct_owner_occupied', 'pct_rental', 'population_total', 'year'\n",
    "]\n",
    "\n",
    "print(f\"\\nTargets: {batch2_targets}\")\n",
    "print(f\"Context features: {len(batch2_context)} features\")\n",
    "\n",
    "df = knn_impute(df, batch2_targets, batch2_context, k=5)\n",
    "\n",
    "print(f\"\\n  Validation - Imputed income variables:\")\n",
    "for var in batch2_targets:\n",
    "    if var in df.columns:\n",
    "        print(f\"\\n  {var}:\")\n",
    "        print(f\"    Mean: {df[var].mean():.2f}\")\n",
    "        print(f\"    Median: {df[var].median():.2f}\")\n",
    "        print(f\"    Min: {df[var].min():.2f}\")\n",
    "        print(f\"    Max: {df[var].max():.2f}\")\n",
    "        print(f\"    Still missing: {df[var].isnull().sum()}\")\n",
    "\n",
    "# ============================================================\n",
    "# BATCH 3: Education and household composition\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BATCH 3: Education and Household Composition\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch3_targets = ['n_high_education', 'avg_household_size']\n",
    "batch3_context = [\n",
    "    'urbanicity',\n",
    "    'income_household', 'woz_value',\n",
    "    'population_total', 'pop_age_25_45', 'pop_age_45_65', 'pop_age_65_plus', 'year'\n",
    "]\n",
    "\n",
    "print(f\"\\nTargets: {batch3_targets}\")\n",
    "print(f\"Context features: {len(batch3_context)} features\")\n",
    "\n",
    "df = knn_impute(df, batch3_targets, batch3_context, k=5)\n",
    "\n",
    "print(f\"\\n  Validation - Imputed education/household variables:\")\n",
    "for var in batch3_targets:\n",
    "    if var in df.columns:\n",
    "        print(f\"\\n  {var}:\")\n",
    "        print(f\"    Mean: {df[var].mean():.2f}\")\n",
    "        print(f\"    Median: {df[var].median():.2f}\")\n",
    "        print(f\"    Min: {df[var].min():.2f}\")\n",
    "        print(f\"    Max: {df[var].max():.2f}\")\n",
    "        print(f\"    Still missing: {df[var].isnull().sum()}\")\n",
    "\n",
    "# ============================================================\n",
    "# BATCH 4: Facility variables\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BATCH 4: Facility Variables\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "facility_vars = [\n",
    "    'restaurants_1km',\n",
    "    'cafes_1km',\n",
    "    'cafeterias_1km',\n",
    "    'dist_primary_school',\n",
    "    'dist_train_station',\n",
    "    'supermarkets_1km',\n",
    "    'food_shops_1km',\n",
    "    'dist_secondary_school',\n",
    "]\n",
    "facility_context = [\n",
    "    'urbanicity',\n",
    "    'population_total',\n",
    "    'avg_household_size',\n",
    "    'woz_value',\n",
    "    'income_household',\n",
    "    'year'\n",
    "]\n",
    "\n",
    "print(f\"\\nTargets: {facility_vars}\")\n",
    "print(f\"Context features: {len(facility_context)} features\")\n",
    "\n",
    "df = knn_impute(df, facility_vars, facility_context, k=5)\n",
    "\n",
    "print(f\"\\n  Validation - Imputed facility variables:\")\n",
    "for var in facility_vars:\n",
    "    if var in df.columns:\n",
    "        print(f\"\\n  {var}:\")\n",
    "        print(f\"    Mean: {df[var].mean():.2f}\")\n",
    "        print(f\"    Median: {df[var].median():.2f}\")\n",
    "        print(f\"    Min: {df[var].min():.2f}\")\n",
    "        print(f\"    Max: {df[var].max():.2f}\")\n",
    "        print(f\"    Still missing: {df[var].isnull().sum()}\")\n",
    "\n",
    "# ============================================================\n",
    "# FINAL SUMMARY AND VALIDATION\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY: Missing values after all batches\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "missing_after = df.isnull().sum()\n",
    "print(missing_after[missing_after > 0].sort_values(ascending=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Comparing with non-imputed dataset\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    df_original = pd.read_csv('non_imputed_merged_buurt_panel_data.csv', na_values=['.', '..', ''])\n",
    "    \n",
    "    # Combine all imputed variables for comparison\n",
    "    all_imputed_vars = relevant_vars + facility_vars\n",
    "    \n",
    "    print(\"\\nImputation effectiveness:\")\n",
    "    for var in all_imputed_vars:\n",
    "        if var in df.columns and var in df_original.columns:\n",
    "            before_missing = df_original[var].isnull().sum()\n",
    "            after_missing = df[var].isnull().sum()\n",
    "            improvement = before_missing - after_missing\n",
    "            if before_missing > 0:\n",
    "                print(f\"  {var}:\")\n",
    "                print(f\"    Before: {before_missing} missing ({100*before_missing/len(df):.1f}%)\")\n",
    "                print(f\"    After: {after_missing} missing ({100*after_missing/len(df):.1f}%)\")\n",
    "                print(f\"    Improvement: {improvement} values imputed ({100*improvement/before_missing:.1f}% of missing)\")\n",
    "except FileNotFoundError:\n",
    "    print(\"  Non-imputed file not found for comparison\")\n",
    "\n",
    "# ============================================================\n",
    "# SAVE IMPUTED DATASET\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Saving imputed dataset\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df.to_csv('../data/merged_buurt_panel_data_imputed.csv', index=False)\n",
    "print(\"✓ Saved: merged_buurt_panel_data_imputed.csv\")\n",
    "\n",
    "print(f\"\\nFinal dataset:\")\n",
    "print(f\"  Rows: {len(df)}\")\n",
    "print(f\"  Columns: {len(df.columns)}\")\n",
    "print(f\"  Complete cases (no missing): {df.dropna().shape[0]}\")\n",
    "print(f\"  Rows by year:\\n{df['year'].value_counts().sort_index()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Ready for DiD analysis!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_targets = batch1_targets + batch2_targets + batch3_targets + facility_vars\n",
    "complete_vars = [v for v in all_targets if v in df.columns and df[v].notna().all()]\n",
    "incomplete_vars = [v for v in all_targets if v in df.columns and df[v].isnull().any()]\n",
    "\n",
    "print(f\"\\nVariables status:\")\n",
    "print(f\"  Complete (no missing): {complete_vars}\")\n",
    "print(f\"  Incomplete (still missing): {incomplete_vars}\")\n",
    "print(f\"\\nKey variables for analysis:\")\n",
    "print(f\"  Treatment: green_coverage_pct_2020, green_coverage_pct_2024\")\n",
    "print(f\"  Outcomes: income_household, income_inhabitant, pct_low_income, woz_value\")\n",
    "print(f\"  Controls: urbanicity, population_total, facilities, housing characteristics\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
